{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DWzS3wXGtWRT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import random\n",
    "import torchaudio\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Evqqe4pG8k3z",
    "outputId": "b9003d1d-4fba-40f4-aa63-58deb401a5c8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 26 01:22:49 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 32%   50C    P3             141W / 350W |    520MiB / 24576MiB |      9%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      2753      G   /usr/lib/xorg/Xorg                          295MiB |\r\n",
      "|    0   N/A  N/A      2873      G   /usr/bin/gnome-shell                         47MiB |\r\n",
      "|    0   N/A  N/A      5848      G   ...sion,SpareRendererForSitePerProcess       27MiB |\r\n",
      "|    0   N/A  N/A      6179      G   ...1365742,11007510766059727277,262144      113MiB |\r\n",
      "|    0   N/A  N/A     87329      G   /opt/teamviewer/tv_bin/TeamViewer            13MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni3W9xIGXG1Z"
   },
   "source": [
    "## Load GoEmotions and General Audio Datasets (CREMA, TESS,  RAVDASS, ETC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VJWwfnsutyBN"
   },
   "outputs": [],
   "source": [
    "train_audio = pkl.load(open('/home/vmachado/Documents/c4ai_clip_audio_text/data/c4ai_clip/train_audio.pkl', \"rb\"))[['path', 'label']]\n",
    "test_audio = pkl.load(open('/home/vmachado/Documents/c4ai_clip_audio_text/data/c4ai_clip/test_audio.pkl', \"rb\"))[['path', 'label']]\n",
    "train_text = pkl.load(open('/home/vmachado/Documents/c4ai_clip_audio_text/data/c4ai_clip/train_text.pkl', \"rb\"))[['text', 'grouped_label']]\n",
    "test_text = pkl.load(open('/home/vmachado/Documents/c4ai_clip_audio_text/data/c4ai_clip/test_text.pkl', \"rb\"))[['text', 'grouped_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ov6R_5UhfUd7",
    "outputId": "9d35f7b5-a38e-4b6e-8be2-daf38365486e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>6039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>19002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>14429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>2936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>5062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "grouped_label       \n",
       "anger           6039\n",
       "disgust          664\n",
       "fear             705\n",
       "joy            19002\n",
       "neutral        14429\n",
       "sadness         2936\n",
       "surprise        5062"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_emotions.groupby(\"grouped_label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = go_emotions[go_emotions[\"grouped_label\"] == \"anger\"].sample(5000, replace=False, random_state=0)\n",
    "disgust = go_emotions[go_emotions[\"grouped_label\"] == \"disgust\"].sample(4000, replace=True, random_state=0)\n",
    "fear = go_emotions[go_emotions[\"grouped_label\"] == \"fear\"].sample(4000, replace=True, random_state=0)\n",
    "joy = go_emotions[go_emotions[\"grouped_label\"] == \"joy\"].sample(5000, replace=False, random_state=0)\n",
    "neutral = go_emotions[go_emotions[\"grouped_label\"] == \"neutral\"].sample(5000, replace=False, random_state=0)\n",
    "sadness = go_emotions[go_emotions[\"grouped_label\"] == \"sadness\"].sample(2000, replace=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>4664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>4705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>4936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>5062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text\n",
       "grouped_label      \n",
       "anger          5000\n",
       "disgust        4664\n",
       "fear           4705\n",
       "joy            5000\n",
       "neutral        5000\n",
       "sadness        4936\n",
       "surprise       5062"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_emotions = go_emotions[go_emotions[\"grouped_label\"] != \"anger\"]\n",
    "go_emotions = go_emotions[go_emotions[\"grouped_label\"] != \"joy\"]\n",
    "go_emotions = go_emotions[go_emotions[\"grouped_label\"] != \"neutral\"]\n",
    "go_emotions = pd.concat([go_emotions, anger, disgust, fear, joy, neutral, sadness])\n",
    "go_emotions.groupby(\"grouped_label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kwdbm_LN0wVk"
   },
   "outputs": [],
   "source": [
    "def norm_labels(x):\n",
    "    if x == \"afraid\":\n",
    "        return \"fear\"\n",
    "    elif x == \"angry\":\n",
    "        return \"anger\"\n",
    "    elif x == \"disgusted\":\n",
    "        return \"disgust\"\n",
    "    elif x == \"sad\":\n",
    "        return \"sadness\"\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XefjoUugGJe9"
   },
   "outputs": [],
   "source": [
    "train_audio[\"label\"] = train_audio[\"label\"].apply(norm_labels)\n",
    "test_audio[\"label\"] = test_audio[\"label\"].apply(norm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "pIcNuJ6sjPt8",
    "outputId": "71110be1-2732-4d72-e8fa-3023f6f9632b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          path\n",
       "label         \n",
       "anger     1863\n",
       "disgust   1863\n",
       "fear      1863\n",
       "joy       2055\n",
       "neutral   1583\n",
       "sadness   1863\n",
       "surprise   592"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_audio,test_audio]).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_datasets = pd.concat([train_audio,test_audio]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "surprise = audio_datasets[audio_datasets[\"label\"] == \"surprise\"].sample(2000, replace=True, random_state=0)\n",
    "audio_datasets = audio_datasets[audio_datasets[\"label\"] != \"surprise\"]\n",
    "audio_datasets = pd.concat([audio_datasets, surprise]).reset_index(drop=True)\n",
    "#audio_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          path\n",
       "label         \n",
       "anger     1863\n",
       "disgust   1863\n",
       "fear      1863\n",
       "joy       2055\n",
       "neutral   1583\n",
       "sadness   1863\n",
       "surprise  2000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_datasets.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qk8YSzYOX4H6"
   },
   "source": [
    "## Load Meld and IEMOCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eDL1tDN8MLvT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only one I know still love his parents. [B...</td>\n",
       "      <td>joy</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The only one I know still love his parents. Ye...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh it's not bad thing it's good thing. You kno...</td>\n",
       "      <td>joy</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know it's nice here, the air is sweet. You...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're not sorry you came? Not sorry, no.  I c...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13723</th>\n",
       "      <td>That would be no. Come on. It doesn't taste ba...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>Come on. It doesn't taste bad. Yeah, it's kind...</td>\n",
       "      <td>joy</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>Yeah, it's kinda sweet, sorta like, uh... Cant...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13726</th>\n",
       "      <td>Cantaloupe juice. Exactly. [BFR] You've tasted...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13727</th>\n",
       "      <td>Exactly. You've tasted it? You've tasted it. [...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13728 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  \\\n",
       "0      The only one I know still love his parents. [B...       joy   \n",
       "1      The only one I know still love his parents. Ye...   neutral   \n",
       "2      Oh it's not bad thing it's good thing. You kno...       joy   \n",
       "3      You know it's nice here, the air is sweet. You...   sadness   \n",
       "4      You're not sorry you came? Not sorry, no.  I c...   sadness   \n",
       "...                                                  ...       ...   \n",
       "13723  That would be no. Come on. It doesn't taste ba...   neutral   \n",
       "13724  Come on. It doesn't taste bad. Yeah, it's kind...       joy   \n",
       "13725  Yeah, it's kinda sweet, sorta like, uh... Cant...   neutral   \n",
       "13726  Cantaloupe juice. Exactly. [BFR] You've tasted...  surprise   \n",
       "13727  Exactly. You've tasted it? You've tasted it. [...   neutral   \n",
       "\n",
       "                                                    path  \n",
       "0      /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "1      /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "2      /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "3      /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "4      /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "...                                                  ...  \n",
       "13723  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "13724  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "13725  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "13726  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "13727  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "\n",
       "[13728 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_erc = pd.read_csv(\"train_text_df.csv\", index_col=0).rename(columns={\"utterance\":\"text\"})\n",
    "train_df_erc[\"path\"] = train_df_erc[\"path\"].apply(lambda x: '/home/vmachado/Documents/' + x)\n",
    "train_df_erc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDKLMwOQX-6Z",
    "outputId": "ba1fa968-71e1-4f41-a9c0-42367a4d7a89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BFR] Brian, I need help. [AFT] Babe, I don't...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian, I need help. [BFR] Babe, I don't know w...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babe, I don't know what to tell you.  Don't gi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wish I had some answers for you, babe.  I me...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I went to school and I got my degree.  And I g...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>Oh, it is. It isn't. [BFR] It is. [AFT] Isn't!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>It isn't. It is. [BFR] Isn't! [AFT]</td>\n",
       "      <td>anger</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>[BFR] Yeah baby! [AFT] I’m really glad you gu...</td>\n",
       "      <td>joy</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>Yeah baby! [BFR] I’m really glad you guys are ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>Hey.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3851 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    label  \\\n",
       "0      [BFR] Brian, I need help. [AFT] Babe, I don't...  sadness   \n",
       "1     Brian, I need help. [BFR] Babe, I don't know w...  neutral   \n",
       "2     Babe, I don't know what to tell you.  Don't gi...  neutral   \n",
       "3     I wish I had some answers for you, babe.  I me...  neutral   \n",
       "4     I went to school and I got my degree.  And I g...  neutral   \n",
       "...                                                 ...      ...   \n",
       "3846     Oh, it is. It isn't. [BFR] It is. [AFT] Isn't!  neutral   \n",
       "3847               It isn't. It is. [BFR] Isn't! [AFT]     anger   \n",
       "3848   [BFR] Yeah baby! [AFT] I’m really glad you gu...      joy   \n",
       "3849  Yeah baby! [BFR] I’m really glad you guys are ...  neutral   \n",
       "3850                                               Hey.  neutral   \n",
       "\n",
       "                                                   path  \n",
       "0     /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "1     /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "2     /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "3     /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "4     /home/vmachado/Documents/multimodal-datasets/I...  \n",
       "...                                                 ...  \n",
       "3846  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "3847  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "3848  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "3849  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "3850  /home/vmachado/Documents/multimodal-datasets/M...  \n",
       "\n",
       "[3851 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_erc = pd.read_csv(\"test_text_df.csv\", index_col=0).rename(columns={\"utterance\":\"text\"})\n",
    "test_df_erc[\"path\"] = test_df_erc[\"path\"].apply(lambda x: '/home/vmachado/Documents/' + x)\n",
    "test_df_erc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BFR] Brian, I need help. [AFT] Babe, I don't...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "      <td>iemocap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian, I need help. [BFR] Babe, I don't know w...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "      <td>iemocap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babe, I don't know what to tell you.  Don't gi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "      <td>iemocap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wish I had some answers for you, babe.  I me...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "      <td>iemocap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I went to school and I got my degree.  And I g...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/I...</td>\n",
       "      <td>iemocap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>Oh, it is. It isn't. [BFR] It is. [AFT] Isn't!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "      <td>meld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>It isn't. It is. [BFR] Isn't! [AFT]</td>\n",
       "      <td>anger</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "      <td>meld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>[BFR] Yeah baby! [AFT] I’m really glad you gu...</td>\n",
       "      <td>joy</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "      <td>meld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>Yeah baby! [BFR] I’m really glad you guys are ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "      <td>meld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>Hey.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/vmachado/Documents/multimodal-datasets/M...</td>\n",
       "      <td>meld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3851 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    label  \\\n",
       "0      [BFR] Brian, I need help. [AFT] Babe, I don't...  sadness   \n",
       "1     Brian, I need help. [BFR] Babe, I don't know w...  neutral   \n",
       "2     Babe, I don't know what to tell you.  Don't gi...  neutral   \n",
       "3     I wish I had some answers for you, babe.  I me...  neutral   \n",
       "4     I went to school and I got my degree.  And I g...  neutral   \n",
       "...                                                 ...      ...   \n",
       "3846     Oh, it is. It isn't. [BFR] It is. [AFT] Isn't!  neutral   \n",
       "3847               It isn't. It is. [BFR] Isn't! [AFT]     anger   \n",
       "3848   [BFR] Yeah baby! [AFT] I’m really glad you gu...      joy   \n",
       "3849  Yeah baby! [BFR] I’m really glad you guys are ...  neutral   \n",
       "3850                                               Hey.  neutral   \n",
       "\n",
       "                                                   path   source  \n",
       "0     /home/vmachado/Documents/multimodal-datasets/I...  iemocap  \n",
       "1     /home/vmachado/Documents/multimodal-datasets/I...  iemocap  \n",
       "2     /home/vmachado/Documents/multimodal-datasets/I...  iemocap  \n",
       "3     /home/vmachado/Documents/multimodal-datasets/I...  iemocap  \n",
       "4     /home/vmachado/Documents/multimodal-datasets/I...  iemocap  \n",
       "...                                                 ...      ...  \n",
       "3846  /home/vmachado/Documents/multimodal-datasets/M...     meld  \n",
       "3847  /home/vmachado/Documents/multimodal-datasets/M...     meld  \n",
       "3848  /home/vmachado/Documents/multimodal-datasets/M...     meld  \n",
       "3849  /home/vmachado/Documents/multimodal-datasets/M...     meld  \n",
       "3850  /home/vmachado/Documents/multimodal-datasets/M...     meld  \n",
       "\n",
       "[3851 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_erc[\"source\"] = test_df_erc[\"path\"].apply(lambda x: \"meld\" if \"MELD\" in x else \"iemocap\")\n",
    "test_df_erc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iemocap</th>\n",
       "      <td>1241</td>\n",
       "      <td>1241</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meld</th>\n",
       "      <td>2610</td>\n",
       "      <td>2610</td>\n",
       "      <td>2610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text  label  path\n",
       "source                    \n",
       "iemocap  1241   1241  1241\n",
       "meld     2610   2610  2610"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_erc.groupby(\"source\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXbw47lffnBL"
   },
   "source": [
    "## Join datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3qhKJxnIv2ma"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>1954</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>2783</td>\n",
       "      <td>2783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>5804</td>\n",
       "      <td>5804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>1451</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>1212</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text  path\n",
       "label               \n",
       "anger     1954  1954\n",
       "disgust    258   258\n",
       "fear       266   266\n",
       "joy       2783  2783\n",
       "neutral   5804  5804\n",
       "sadness   1451  1451\n",
       "surprise  1212  1212"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_erc.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RJQ3Ky9xkew8"
   },
   "outputs": [],
   "source": [
    "ang = train_df_erc[train_df_erc[\"label\"] == \"anger\"].sample(3000, replace=True, random_state=0)\n",
    "disg = train_df_erc[train_df_erc[\"label\"] == \"disgust\"].sample(4700, replace=True, random_state=0)\n",
    "fear = train_df_erc[train_df_erc[\"label\"] == \"fear\"].sample(4700, replace=True, random_state=0)\n",
    "joy = train_df_erc[train_df_erc[\"label\"] == \"joy\"].sample(2300, replace=True, random_state=0)\n",
    "sadness = train_df_erc[train_df_erc[\"label\"] == \"sadness\"].sample(3500, replace=True, random_state=0)\n",
    "surprise = train_df_erc[train_df_erc[\"label\"] == \"surprise\"].sample(3800, replace=True, random_state=0)\n",
    "\n",
    "#excited = train_df_erc[train_df_erc[\"label\"] == \"excited\"].sample(4300, replace=True, random_state=0)\n",
    "#frustration = train_df_erc[train_df_erc[\"label\"] == \"frustration\"].sample(3600, replace=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_erc_resampled = pd.concat([train_df_erc, joy, ang, disg, fear, surprise, sadness, excited, frustration]).reset_index(drop=True)\n",
    "train_df_erc_resampled = pd.concat([train_df_erc, joy, ang, disg, fear, surprise, sadness]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_erc_resampled = train_df_erc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNjRZbK4xcOB",
    "outputId": "b8589e93-9a56-494f-a9f8-6e38a4672f01",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>4954</td>\n",
       "      <td>4954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>4958</td>\n",
       "      <td>4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>4966</td>\n",
       "      <td>4966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>5083</td>\n",
       "      <td>5083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>5804</td>\n",
       "      <td>5804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>4951</td>\n",
       "      <td>4951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>5012</td>\n",
       "      <td>5012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text  path\n",
       "label               \n",
       "anger     4954  4954\n",
       "disgust   4958  4958\n",
       "fear      4966  4966\n",
       "joy       5083  5083\n",
       "neutral   5804  5804\n",
       "sadness   4951  4951\n",
       "surprise  5012  5012"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_erc_resampled.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VoxPopuli + VoxCeleb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>and i i don't believe in god no religion says ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>the question because of my mother till i was f...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>from my own culture things changed i i think a...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>of god what is a creator the almighty that uh</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>i don't wanna pinpoint what exactly god is i i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>the movie while he's solving this mystery exce...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>in my backstory you know that i actually uh hi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>and it's just high action uh uh you want you</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>you you can't stop thinking and and wondering ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7165</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>and very flattering it's you know because i gr...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7166 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  \\\n",
       "0     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "1     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "2     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "3     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "4     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "...                                                 ...   \n",
       "7161  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "7162  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "7163  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "7164  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "7165  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "\n",
       "                                                   text sentiment_label  \n",
       "0     and i i don't believe in god no religion says ...         Neutral  \n",
       "1     the question because of my mother till i was f...         Neutral  \n",
       "2     from my own culture things changed i i think a...         Neutral  \n",
       "3         of god what is a creator the almighty that uh         Neutral  \n",
       "4     i don't wanna pinpoint what exactly god is i i...         Neutral  \n",
       "...                                                 ...             ...  \n",
       "7161  the movie while he's solving this mystery exce...         Neutral  \n",
       "7162  in my backstory you know that i actually uh hi...         Neutral  \n",
       "7163       and it's just high action uh uh you want you         Neutral  \n",
       "7164  you you can't stop thinking and and wondering ...         Neutral  \n",
       "7165  and very flattering it's you know because i gr...         Neutral  \n",
       "\n",
       "[7166 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vox = pd.read_csv(\"voxceleb.csv\").drop(columns=\"Unnamed: 0\")[[\"path\", \"text\", \"sentiment_label\"]]\n",
    "df_vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>and i i don't believe in god no religion says ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>the question because of my mother till i was f...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>from my own culture things changed i i think a...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>of god what is a creator the almighty that uh</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>i don't wanna pinpoint what exactly god is i i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>the movie while he's solving this mystery exce...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>in my backstory you know that i actually uh hi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>and it's just high action uh uh you want you</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>you you can't stop thinking and and wondering ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7165</th>\n",
       "      <td>/home/vmachado/.cache/huggingface/datasets/dow...</td>\n",
       "      <td>and very flattering it's you know because i gr...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7166 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  \\\n",
       "0     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "1     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "2     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "3     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "4     /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "...                                                 ...   \n",
       "7161  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "7162  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "7163  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "7164  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "7165  /home/vmachado/.cache/huggingface/datasets/dow...   \n",
       "\n",
       "                                                   text sentiment_label  \n",
       "0     and i i don't believe in god no religion says ...         Neutral  \n",
       "1     the question because of my mother till i was f...         Neutral  \n",
       "2     from my own culture things changed i i think a...         Neutral  \n",
       "3         of god what is a creator the almighty that uh         Neutral  \n",
       "4     i don't wanna pinpoint what exactly god is i i...         Neutral  \n",
       "...                                                 ...             ...  \n",
       "7161  the movie while he's solving this mystery exce...         Neutral  \n",
       "7162  in my backstory you know that i actually uh hi...         Neutral  \n",
       "7163       and it's just high action uh uh you want you         Neutral  \n",
       "7164  you you can't stop thinking and and wondering ...         Neutral  \n",
       "7165  and very flattering it's you know because i gr...         Neutral  \n",
       "\n",
       "[7166 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ls = pd.read_csv(\"voxceleb.csv\").drop(columns=\"Unnamed: 0\")[[\"path\", \"text\", \"sentiment_label\"]] #pd.read_csv(\"df_ls.csv\")\n",
    "df_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYBBNw5txuTr",
    "outputId": "a9b71212-2cdb-43f7-c1d8-626bfef56dff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demographics? I don’t know anybody under 35 wh...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maybe that’s what happened to the great white ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I never thought it was at the same moment, but...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.351.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/ravdass.man.surprise.63.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.26.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.67.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90350</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/ravdass.man.surprise.52.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90351 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  \\\n",
       "0                            To make her feel threatened      fear   \n",
       "1      OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...  surprise   \n",
       "2      Demographics? I don’t know anybody under 35 wh...  surprise   \n",
       "3      Maybe that’s what happened to the great white ...  surprise   \n",
       "4      I never thought it was at the same moment, but...  surprise   \n",
       "...                                                  ...       ...   \n",
       "90346                                                NaN  surprise   \n",
       "90347                                                NaN  surprise   \n",
       "90348                                                NaN  surprise   \n",
       "90349                                                NaN  surprise   \n",
       "90350                                                NaN  surprise   \n",
       "\n",
       "                                                 path sentiment_label  \n",
       "0                                                None             NaN  \n",
       "1                                                None             NaN  \n",
       "2                                                None             NaN  \n",
       "3                                                None             NaN  \n",
       "4                                                None             NaN  \n",
       "...                                               ...             ...  \n",
       "90346  ./audio/audio_emo/tess.woman.surprised.351.wav             NaN  \n",
       "90347   ./audio/audio_emo/ravdass.man.surprise.63.wav             NaN  \n",
       "90348   ./audio/audio_emo/tess.woman.surprised.26.wav             NaN  \n",
       "90349   ./audio/audio_emo/tess.woman.surprised.67.wav             NaN  \n",
       "90350   ./audio/audio_emo/ravdass.man.surprise.52.wav             NaN  \n",
       "\n",
       "[90351 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = pd.concat([go_emotions.rename(columns={\"grouped_label\":\"label\"}).assign(path=[None for _ in range(len(go_emotions))]), audio_datasets.assign(text=[None for _ in range(len(audio_datasets))]), train_df_erc_resampled, df_ls]).reset_index(drop=True) #.drop(columns=\"path\")\n",
    "#df_train = pd.concat([audio_datasets.assign(text=[None for _ in range(len(audio_datasets))]), train_df_erc_resampled,train_df_erc_resampled, df_ls]).reset_index(drop=True) #.drop(columns=\"path\")\n",
    "df_train = pd.concat([go_emotions.rename(columns={\"grouped_label\":\"label\"}).assign(path=[None for _ in range(len(go_emotions))]), train_df_erc_resampled, df_ls, audio_datasets]).reset_index(drop=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def label_to_sentiment(x):\n",
    "    if x == None:\n",
    "        return x\n",
    "    if x in [\"joy\", \"surprise\", \"excited\"]:\n",
    "        return \"Positive\"\n",
    "    elif x in [\"fear\", \"anger\", \"disgust\", \"sadness\", \"frustration\"]:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"sentiment_label\"] = df_train[\"label\"].apply(label_to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "      <td>None</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demographics? I don’t know anybody under 35 wh...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maybe that’s what happened to the great white ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I never thought it was at the same moment, but...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.351.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/ravdass.man.surprise.63.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.26.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.67.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90350</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/ravdass.man.surprise.52.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90351 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  \\\n",
       "0                            To make her feel threatened      fear   \n",
       "1      OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...  surprise   \n",
       "2      Demographics? I don’t know anybody under 35 wh...  surprise   \n",
       "3      Maybe that’s what happened to the great white ...  surprise   \n",
       "4      I never thought it was at the same moment, but...  surprise   \n",
       "...                                                  ...       ...   \n",
       "90346                                                NaN  surprise   \n",
       "90347                                                NaN  surprise   \n",
       "90348                                                NaN  surprise   \n",
       "90349                                                NaN  surprise   \n",
       "90350                                                NaN  surprise   \n",
       "\n",
       "                                                 path sentiment_label  \n",
       "0                                                None        Negative  \n",
       "1                                                None        Positive  \n",
       "2                                                None        Positive  \n",
       "3                                                None        Positive  \n",
       "4                                                None        Positive  \n",
       "...                                               ...             ...  \n",
       "90346  ./audio/audio_emo/tess.woman.surprised.351.wav        Positive  \n",
       "90347   ./audio/audio_emo/ravdass.man.surprise.63.wav        Positive  \n",
       "90348   ./audio/audio_emo/tess.woman.surprised.26.wav        Positive  \n",
       "90349   ./audio/audio_emo/tess.woman.surprised.67.wav        Positive  \n",
       "90350   ./audio/audio_emo/ravdass.man.surprise.52.wav        Positive  \n",
       "\n",
       "[90351 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    46586\n",
       "Positive    24212\n",
       "Neutral     19553\n",
       "Name: sentiment_label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"sentiment_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "M54RINMGv6I-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "lab_encoder.fit(df_train['label'].unique())\n",
    "\n",
    "lab_encoder_senti = LabelEncoder()\n",
    "lab_encoder_senti.fit(df_train['sentiment_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90351"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjAzuLrExx8Y",
    "outputId": "12a588d1-7ed1-4c03-fc9a-55a40911a149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3851"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df_erc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "b32SE_K1MH38"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import gc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0ogRQkVoSv8",
    "outputId": "3da4fdbf-b45e-44b8-cff5-2c9b857cdf99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9w-KtELjM3BN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "class FaissKNeighbors:\n",
    "    def __init__(self, k=5):\n",
    "        self.index = None\n",
    "        self.y = None\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.index = faiss.IndexFlatL2(X.shape[1])\n",
    "        self.index.add(X.astype(np.float32))\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances, indices = self.index.search(X.astype(np.float32), k=self.k)\n",
    "        votes = self.y[indices]\n",
    "        predictions = np.array([np.argmax(np.bincount(x)) for x in votes])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class Scheduler(_LRScheduler):\n",
    "    def __init__(self, \n",
    "                 optimizer: Optimizer,\n",
    "                 dim_embed: int,\n",
    "                 warmup_steps: int,\n",
    "                 last_epoch: int=-1,\n",
    "                 verbose: bool=False) -> None:\n",
    "\n",
    "        self.dim_embed = dim_embed\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.num_param_groups = len(optimizer.param_groups)\n",
    "\n",
    "        super().__init__(optimizer, last_epoch, verbose)\n",
    "        \n",
    "    def get_lr(self) -> float:\n",
    "        lr = calc_lr(self._step_count, self.dim_embed, self.warmup_steps)\n",
    "        return [lr] * self.num_param_groups\n",
    "\n",
    "global PREVIOUS_LR\n",
    "PREVIOUS_LR = -9999\n",
    "def calc_lr(step, dim_embed, warmup_steps):\n",
    "    #if step > warmup_steps:\n",
    "    #    return 5e-5\n",
    "    global PREVIOUS_LR\n",
    "    lr = dim_embed**(-0.5) * min(step**(-0.5), step * warmup_steps**(-1.5))\n",
    "    #return lr\n",
    "    if lr < 2e-4:\n",
    "        PREVIOUS_LR = lr\n",
    "        return lr\n",
    "    else:\n",
    "        #lr = dim_embed**(-0.5) * min(step**(-0.5), step * warmup_steps**(-1.5))\n",
    "        while lr >= PREVIOUS_LR:\n",
    "            step += 1.\n",
    "            lr = dim_embed**(-0.5) * min(step**(-0.5), step * warmup_steps**(-1.5))\n",
    "        PREVIOUS_LR = lr\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.speech_encoder import *\n",
    "\n",
    "dim_embed = 768\n",
    "N_VECTORS = 512\n",
    "MAX_LEN = 256\n",
    "\n",
    "audio_encoder = AudioEncoderMFCCHU(\n",
    "    N_VECTORS, \n",
    "    emb_dim=dim_embed, \n",
    "    n_layers=1, \n",
    "    max_length=MAX_LEN, \n",
    "    nheads=12,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "#audio_encoder = torch.load(f'/home/vmachado/Documents/c4ai_clip_audio_text/audio_encoder_best/audio_encoder.bin')\n",
    "#audio_encoder.load_state_dict(torch.load(f'/home/vmachado/Documents/c4ai_clip_audio_text/audio_encoder_pre_trained_reformed_5_FIM_6_layer_continue/audio_best.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.text_encoder import *\n",
    "\n",
    "MODEL_NAME = 'sentence-transformers/all-mpnet-base-v2'\n",
    "#MODEL_NAME = 'sentence-transformers/all-MiniLM-L12-v2'\n",
    "text_encoder = TextEncoder(MODEL_NAME, max_len=128, extra_tokens=['[NAME]', '[RELIGION]', '[LAUGHTER]', '[BFR]', '[AFT]'])\n",
    "#text_encoder.load_state_dict(torch.load('/home/vmachado/Documents/c4ai_clip_audio_text/text_encoder_only_meld/dabest_text.bin'))\n",
    "#text_encoder.load_state_dict(torch.load(f'text_encoder_ready_L2_test2/best_text_encoder.bin'))\n",
    "#text_encoder.load_state_dict(torch.load(f'text_encoder_ready_L2_test2/pytorch_model_AudioTextCLIP_epoch_22.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in list(text_encoder.parameters()):\n",
    "    param.requires_grad = True\n",
    "    \n",
    "#for idx_l, l in enumerate(text_encoder.encoder.encoder.layer):\n",
    "#    if idx_l >= 11:\n",
    "#        for param in list(l.parameters()):\n",
    "#            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "      <td>None</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demographics? I don’t know anybody under 35 wh...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maybe that’s what happened to the great white ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I never thought it was at the same moment, but...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.351.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/ravdass.man.surprise.63.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.26.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/tess.woman.surprised.67.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90350</th>\n",
       "      <td>NaN</td>\n",
       "      <td>surprise</td>\n",
       "      <td>./audio/audio_emo/ravdass.man.surprise.52.wav</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90351 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  \\\n",
       "0                            To make her feel threatened      fear   \n",
       "1      OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...  surprise   \n",
       "2      Demographics? I don’t know anybody under 35 wh...  surprise   \n",
       "3      Maybe that’s what happened to the great white ...  surprise   \n",
       "4      I never thought it was at the same moment, but...  surprise   \n",
       "...                                                  ...       ...   \n",
       "90346                                                NaN  surprise   \n",
       "90347                                                NaN  surprise   \n",
       "90348                                                NaN  surprise   \n",
       "90349                                                NaN  surprise   \n",
       "90350                                                NaN  surprise   \n",
       "\n",
       "                                                 path sentiment_label  \n",
       "0                                                None        Negative  \n",
       "1                                                None        Positive  \n",
       "2                                                None        Positive  \n",
       "3                                                None        Positive  \n",
       "4                                                None        Positive  \n",
       "...                                               ...             ...  \n",
       "90346  ./audio/audio_emo/tess.woman.surprised.351.wav        Positive  \n",
       "90347   ./audio/audio_emo/ravdass.man.surprise.63.wav        Positive  \n",
       "90348   ./audio/audio_emo/tess.woman.surprised.26.wav        Positive  \n",
       "90349   ./audio/audio_emo/tess.woman.surprised.67.wav        Positive  \n",
       "90350   ./audio/audio_emo/ravdass.man.surprise.52.wav        Positive  \n",
       "\n",
       "[90351 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M039.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_M043.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_3_F030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_2_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M042.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F042.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M043.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M044.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F043.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F044.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M046.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M047.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F045.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F046.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M048.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_F047.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_2_M049.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_F034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_F035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_F037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_F038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M039.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_M040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_F041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script01_1_F042.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro06_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F039.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M039.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_F040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script03_2_M040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro02_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro02_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro05_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_M042.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script02_1_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro03_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_F035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro06_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_script01_2_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_F029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script03_1_M034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro07_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro03_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02M_impro05_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F042.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M042.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F044.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F046.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F047.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F048.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M045.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_F049.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script02_2_M046.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_F030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_impro05b_M033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M042.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M045.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M046.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M047.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F045.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F046.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M049.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M050.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F050.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_M052.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F052.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_script01_1_F053.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_M030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_impro06_F028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_impro07_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M039.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M043.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M044.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M045.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script02_1_M046.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M033.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_M043.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01F_script02_1_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F032.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F034.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F035.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M025.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F039.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F042.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_F043.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03F_impro02_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M014.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F023.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M024.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_M026.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro03_F030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_M015.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses01M_script01_2_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F010.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_impro02_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M001.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M003.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M009.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M011.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M019.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F020.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F021.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M022.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M027.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M028.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M029.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M031.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F030.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M036.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M037.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M039.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F038.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M041.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F040.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M043.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F043.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M045.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_M047.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses03M_script01_1_F046.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M002.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M004.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_F005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M005.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M006.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M007.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M008.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_F012.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_F013.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M016.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M017.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses02F_script01_2_M018.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro04_F000.wav',\n",
       " '/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/train/Ses04F_impro04_M001.wav',\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_train[~df_train[\"path\"].isna()][\"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.speech_processing import *\n",
    "\n",
    "audio_tokenizer = AudioEncoderMFCCHUTokenizer(max_length=MAX_LEN, cache_path='/home/vmachado/Documents/c4ai_clip_audio_text/new_speech_features/')\n",
    "#_, lens = audio_tokenizer.cache_dataset(paths=list(df_train[~df_train[\"path\"].isna()].sample(frac=0.25, random_state=0)[\"path\"]))\n",
    "audio_tokenizer.mean = torch.Tensor([-1.1745e+03,  2.2787e+00, -1.3436e+02,  4.2281e+01, -1.5886e+02,\n",
    "        -4.2503e+01, -1.6652e+02, -6.0679e+01, -1.0516e+02, -3.1940e+01,\n",
    "        -9.4301e+01, -2.8196e+01, -6.6406e+01,  1.3214e-01,  2.4173e-01,\n",
    "         2.1768e-01,  1.9153e-01,  1.5862e-01,  1.3224e-01,  1.1713e-01,\n",
    "         1.0544e-01,  9.4641e-02,  8.5885e-02,  7.7632e-02,  7.0888e-02,\n",
    "         6.3016e-02,  5.7492e-02,  5.2733e-02,  4.8752e-02,  4.4427e-02,\n",
    "         4.0783e-02,  3.6457e-02,  3.3371e-02,  3.0200e-02,  2.7740e-02,\n",
    "         2.4798e-02,  2.2748e-02,  2.0403e-02,  1.8943e-02,  1.7292e-02,\n",
    "         1.5884e-02,  1.4463e-02,  1.3473e-02,  1.2383e-02,  1.1698e-02,\n",
    "         1.0816e-02,  1.0040e-02,  9.2574e-03,  8.7220e-03,  8.0053e-03,\n",
    "         7.3996e-03,  6.8473e-03,  6.4102e-03,  5.8573e-03,  5.4198e-03,\n",
    "         4.9593e-03,  4.6220e-03,  4.2688e-03,  4.0196e-03,  3.7833e-03,\n",
    "         3.5817e-03,  3.3637e-03,  3.2097e-03,  3.0329e-03,  2.9024e-03,\n",
    "         2.7216e-03,  2.5992e-03,  2.4578e-03,  2.3219e-03,  2.2085e-03,\n",
    "         2.1044e-03,  1.9795e-03,  1.8923e-03,  1.7711e-03,  1.6752e-03,\n",
    "         1.5630e-03,  1.5008e-03,  1.4268e-03,  1.3523e-03,  1.2771e-03,\n",
    "         1.2057e-03,  1.1288e-03,  1.0627e-03,  1.0068e-03,  9.3696e-04,\n",
    "         8.8309e-04,  8.2027e-04,  7.7626e-04,  7.2621e-04,  6.8244e-04,\n",
    "         6.2516e-04,  5.7361e-04,  5.4662e-04,  5.0724e-04,  4.7727e-04,\n",
    "         4.4075e-04,  4.0421e-04,  3.6961e-04,  3.3435e-04,  3.0521e-04,\n",
    "         2.8062e-04,  2.6401e-04,  2.3755e-04,  2.1533e-04,  1.9300e-04,\n",
    "         1.7130e-04,  1.5586e-04,  1.4436e-04,  1.2694e-04,  1.1913e-04,\n",
    "         1.0666e-04,  9.7559e-05,  8.8004e-05,  8.0929e-05,  7.5713e-05,\n",
    "         6.5684e-05,  6.2502e-05,  5.5034e-05,  4.8409e-05,  4.3191e-05,\n",
    "         3.9435e-05,  3.5874e-05,  3.3941e-05,  3.0259e-05,  2.7158e-05,\n",
    "         2.3242e-05,  1.9884e-05,  1.6042e-05,  8.2821e-02,  2.2356e-01,\n",
    "        -2.8710e-01,  7.9194e-02, -2.2688e-01, -4.4583e-03, -3.1010e-01,\n",
    "        -6.7791e-02, -1.5429e-01, -7.0310e-02, -2.2113e-01, -4.9786e-02,\n",
    "        -1.5399e-01,  2.5206e-04,  4.2298e-04,  4.2356e-04,  3.6397e-04,\n",
    "         3.1303e-04,  2.6955e-04,  2.2263e-04,  2.2512e-04,  2.0992e-04,\n",
    "         1.8997e-04,  1.7311e-04,  1.4846e-04,  1.2123e-04,  1.1412e-04,\n",
    "         1.0339e-04,  1.1267e-04,  1.0309e-04,  8.4783e-05,  7.3514e-05,\n",
    "         7.2023e-05,  6.4760e-05,  6.4285e-05,  5.7985e-05,  5.2177e-05,\n",
    "         4.6418e-05,  4.7871e-05,  4.3763e-05,  4.0681e-05,  3.7222e-05,\n",
    "         3.4295e-05,  3.1561e-05,  2.9967e-05,  2.7680e-05,  2.7623e-05,\n",
    "         2.6451e-05,  2.6466e-05,  2.2476e-05,  2.0828e-05,  1.9829e-05,\n",
    "         1.7483e-05,  1.6071e-05,  1.6325e-05,  1.3802e-05,  1.4725e-05,\n",
    "         1.4710e-05,  1.3431e-05,  1.1905e-05,  1.1559e-05,  1.1739e-05,\n",
    "         1.1275e-05,  1.1417e-05,  1.2092e-05,  1.2754e-05,  1.2024e-05,\n",
    "         1.0824e-05,  1.0315e-05,  9.1208e-06,  8.8483e-06,  7.4808e-06,\n",
    "         7.2708e-06,  8.2807e-06,  7.3811e-06,  7.4967e-06,  6.9180e-06,\n",
    "         7.2903e-06,  6.8355e-06,  5.9609e-06,  5.7615e-06,  5.5132e-06,\n",
    "         5.2766e-06,  4.7307e-06,  4.5198e-06,  3.9687e-06,  3.8545e-06,\n",
    "         3.4617e-06,  3.2478e-06,  2.8526e-06,  3.0319e-06,  2.5946e-06,\n",
    "         2.5531e-06,  2.3268e-06,  2.1778e-06,  2.0740e-06,  1.9709e-06,\n",
    "         1.7363e-06,  1.3544e-06,  1.4028e-06,  1.3077e-06,  1.1276e-06,\n",
    "         1.2016e-06,  1.1983e-06,  1.0208e-06,  8.1538e-07,  7.8428e-07,\n",
    "         6.6318e-07,  7.0989e-07,  9.2021e-07,  7.2013e-07,  8.1444e-07,\n",
    "         8.0237e-07,  9.0007e-07,  6.5921e-07,  6.9934e-07,  3.8494e-07,\n",
    "         4.5313e-07,  4.1900e-07,  3.3735e-07,  2.8976e-07,  3.8101e-07,\n",
    "         2.2933e-07,  2.1375e-07,  1.9388e-07,  1.4123e-07,  6.7112e-08,\n",
    "         5.7247e-08, -4.3037e-01,  6.1246e-02,  5.4988e-02, -3.4926e-02,\n",
    "         1.2448e-01, -1.3948e-03,  1.2025e-01,  4.4583e-02,  9.7096e-02,\n",
    "         1.3381e-02,  8.2258e-02,  2.6150e-02,  7.2660e-02, -1.4877e-04,\n",
    "        -2.4823e-04, -2.3552e-04, -2.2068e-04, -1.6322e-04, -1.2564e-04,\n",
    "        -1.1424e-04, -8.9999e-05, -8.5837e-05, -7.8019e-05, -6.8423e-05,\n",
    "        -6.0470e-05, -5.6134e-05, -5.3471e-05, -4.9815e-05, -4.4360e-05,\n",
    "        -4.5985e-05, -4.3064e-05, -3.7208e-05, -3.6196e-05, -3.3151e-05,\n",
    "        -3.1243e-05, -2.7004e-05, -2.4864e-05, -2.1479e-05, -1.8415e-05,\n",
    "        -1.7921e-05, -1.8757e-05, -1.6076e-05, -1.5099e-05, -1.4192e-05,\n",
    "        -1.2519e-05, -1.1340e-05, -1.0300e-05, -9.5987e-06, -8.8470e-06,\n",
    "        -9.0991e-06, -7.4181e-06, -6.4367e-06, -6.6805e-06, -5.6950e-06,\n",
    "        -5.2952e-06, -5.5317e-06, -4.5829e-06, -4.7052e-06, -4.0624e-06,\n",
    "        -4.2542e-06, -4.2432e-06, -4.1813e-06, -3.5610e-06, -3.1162e-06,\n",
    "        -2.8147e-06, -2.4557e-06, -2.2899e-06, -2.6685e-06, -2.3288e-06,\n",
    "        -2.4319e-06, -2.8676e-06, -2.4296e-06, -2.6144e-06, -1.7675e-06,\n",
    "        -1.7452e-06, -1.6275e-06, -1.6042e-06, -1.3303e-06, -1.4289e-06,\n",
    "        -1.2074e-06, -1.0202e-06, -9.7020e-07, -8.5603e-07, -8.7458e-07,\n",
    "        -6.9110e-07, -9.6283e-07, -8.3394e-07, -9.8441e-07, -7.9333e-07,\n",
    "        -8.3520e-07, -5.1605e-07, -5.8250e-07, -5.1902e-07, -4.7480e-07,\n",
    "        -5.2017e-07, -5.0341e-07, -4.9701e-07, -5.4298e-07, -4.4246e-07,\n",
    "        -4.0207e-07, -4.8091e-07, -3.7359e-07, -3.5006e-07, -3.5082e-07,\n",
    "        -3.1156e-07, -4.0896e-07, -3.3702e-07, -3.5667e-07, -2.9841e-07,\n",
    "        -2.1333e-07, -2.0255e-07, -1.9017e-07, -1.8474e-07, -1.3893e-07,\n",
    "        -2.5546e-07, -2.6200e-07, -2.4044e-07, -1.5338e-07, -1.5324e-07,\n",
    "        -1.0576e-07, -9.9442e-08, -3.9414e-08, -2.2929e-07, -1.4225e-07,\n",
    "        -7.3033e-08, -1.2690e-07, -6.8328e-08, -4.1665e-08]).float()\n",
    "audio_tokenizer.std = torch.Tensor([3.4610e+02, 2.0329e+02, 2.1766e+02, 1.8953e+02, 1.8574e+02, 1.7331e+02,\n",
    "        1.6651e+02, 1.6431e+02, 1.5596e+02, 1.5770e+02, 1.4123e+02, 1.3759e+02,\n",
    "        1.2521e+02, 5.8905e-01, 1.1134e+00, 1.0196e+00, 9.3499e-01, 8.5661e-01,\n",
    "        7.3274e-01, 6.8508e-01, 6.2097e-01, 5.5384e-01, 5.0694e-01, 4.6303e-01,\n",
    "        4.2669e-01, 3.6475e-01, 3.2250e-01, 2.9689e-01, 2.8181e-01, 2.5559e-01,\n",
    "        2.3403e-01, 1.9857e-01, 1.8121e-01, 1.6036e-01, 1.4713e-01, 1.3092e-01,\n",
    "        1.2421e-01, 1.1067e-01, 1.0844e-01, 1.0081e-01, 9.2958e-02, 8.7006e-02,\n",
    "        8.2182e-02, 7.5746e-02, 7.6861e-02, 7.3703e-02, 6.8297e-02, 6.3531e-02,\n",
    "        6.1089e-02, 5.8714e-02, 5.4342e-02, 5.0260e-02, 4.8192e-02, 4.3264e-02,\n",
    "        4.1530e-02, 3.8387e-02, 3.7283e-02, 3.3814e-02, 3.2691e-02, 3.0986e-02,\n",
    "        3.0893e-02, 2.9737e-02, 2.8810e-02, 2.7760e-02, 2.7588e-02, 2.6344e-02,\n",
    "        2.5541e-02, 2.5534e-02, 2.4065e-02, 2.2757e-02, 2.2210e-02, 2.2098e-02,\n",
    "        2.2358e-02, 2.1017e-02, 2.0680e-02, 1.8603e-02, 1.9288e-02, 1.8966e-02,\n",
    "        1.9133e-02, 1.8534e-02, 1.7927e-02, 1.6336e-02, 1.7216e-02, 1.6688e-02,\n",
    "        1.5482e-02, 1.5535e-02, 1.5110e-02, 1.4006e-02, 1.4007e-02, 1.2866e-02,\n",
    "        1.2434e-02, 1.1218e-02, 1.1144e-02, 1.1172e-02, 1.0681e-02, 1.0664e-02,\n",
    "        9.7962e-03, 9.7915e-03, 9.7845e-03, 8.3338e-03, 8.5247e-03, 8.6266e-03,\n",
    "        7.9188e-03, 7.9015e-03, 7.1705e-03, 6.4327e-03, 6.3670e-03, 6.0735e-03,\n",
    "        5.9712e-03, 5.6508e-03, 5.5951e-03, 6.4811e-03, 5.1814e-03, 4.6915e-03,\n",
    "        4.7504e-03, 5.2872e-03, 4.9687e-03, 4.5008e-03, 4.2823e-03, 3.7788e-03,\n",
    "        3.3177e-03, 3.5372e-03, 3.4401e-03, 5.9168e-03, 3.4877e-03, 3.2641e-03,\n",
    "        2.5756e-03, 1.9148e-03, 6.0942e+01, 5.7679e+01, 5.8302e+01, 5.1513e+01,\n",
    "        4.9517e+01, 4.6907e+01, 4.5913e+01, 4.4911e+01, 4.3823e+01, 4.3580e+01,\n",
    "        4.0062e+01, 3.9248e+01, 3.6391e+01, 1.6672e-01, 3.2986e-01, 3.1402e-01,\n",
    "        2.9643e-01, 2.7041e-01, 2.3492e-01, 2.1728e-01, 1.9745e-01, 1.7298e-01,\n",
    "        1.5989e-01, 1.4756e-01, 1.3580e-01, 1.1643e-01, 1.0258e-01, 9.4260e-02,\n",
    "        8.9818e-02, 8.1035e-02, 7.4296e-02, 6.3058e-02, 5.7382e-02, 5.0741e-02,\n",
    "        4.6545e-02, 4.1249e-02, 3.9252e-02, 3.4722e-02, 3.4560e-02, 3.1622e-02,\n",
    "        2.9351e-02, 2.7455e-02, 2.5706e-02, 2.3595e-02, 2.4021e-02, 2.2987e-02,\n",
    "        2.1176e-02, 1.9641e-02, 1.9064e-02, 1.8404e-02, 1.7067e-02, 1.5674e-02,\n",
    "        1.5120e-02, 1.3493e-02, 1.2888e-02, 1.1756e-02, 1.1533e-02, 1.0384e-02,\n",
    "        1.0110e-02, 9.5833e-03, 9.5573e-03, 9.2261e-03, 8.8668e-03, 8.5919e-03,\n",
    "        8.5641e-03, 8.1607e-03, 7.8424e-03, 7.9101e-03, 7.4254e-03, 6.9654e-03,\n",
    "        6.7802e-03, 6.8084e-03, 6.8868e-03, 6.4047e-03, 6.4830e-03, 5.7077e-03,\n",
    "        6.1219e-03, 5.9579e-03, 6.0030e-03, 5.8392e-03, 5.7222e-03, 5.1279e-03,\n",
    "        5.4923e-03, 5.2673e-03, 4.9187e-03, 5.0315e-03, 4.8391e-03, 4.4943e-03,\n",
    "        4.4117e-03, 4.0835e-03, 3.9393e-03, 3.6099e-03, 3.5171e-03, 3.5700e-03,\n",
    "        3.3884e-03, 3.3850e-03, 3.1730e-03, 3.1304e-03, 3.1395e-03, 2.6004e-03,\n",
    "        2.6340e-03, 2.7335e-03, 2.5415e-03, 2.5127e-03, 2.2553e-03, 2.0549e-03,\n",
    "        2.0522e-03, 1.9179e-03, 1.9158e-03, 1.8150e-03, 1.8109e-03, 2.0503e-03,\n",
    "        1.6457e-03, 1.5092e-03, 1.4945e-03, 1.6981e-03, 1.5885e-03, 1.4388e-03,\n",
    "        1.3869e-03, 1.2147e-03, 1.1003e-03, 1.1416e-03, 1.1356e-03, 1.8872e-03,\n",
    "        1.1271e-03, 1.0448e-03, 8.3055e-04, 6.2078e-04, 2.6353e+01, 2.6094e+01,\n",
    "        2.6333e+01, 2.2768e+01, 2.1976e+01, 2.0992e+01, 2.0526e+01, 2.0185e+01,\n",
    "        1.9653e+01, 1.9564e+01, 1.7978e+01, 1.7722e+01, 1.6401e+01, 7.4204e-02,\n",
    "        1.4916e-01, 1.4147e-01, 1.3468e-01, 1.2219e-01, 1.0706e-01, 9.8491e-02,\n",
    "        9.0003e-02, 7.8678e-02, 7.2570e-02, 6.6921e-02, 6.1441e-02, 5.2714e-02,\n",
    "        4.6419e-02, 4.2577e-02, 4.0538e-02, 3.6528e-02, 3.3425e-02, 2.8382e-02,\n",
    "        2.5820e-02, 2.2848e-02, 2.0999e-02, 1.8596e-02, 1.7718e-02, 1.5656e-02,\n",
    "        1.5615e-02, 1.4243e-02, 1.3235e-02, 1.2402e-02, 1.1555e-02, 1.0582e-02,\n",
    "        1.0776e-02, 1.0290e-02, 9.4476e-03, 8.7682e-03, 8.5459e-03, 8.2498e-03,\n",
    "        7.6656e-03, 7.0288e-03, 6.7968e-03, 6.0587e-03, 5.7761e-03, 5.2476e-03,\n",
    "        5.1564e-03, 4.6445e-03, 4.5241e-03, 4.2959e-03, 4.2793e-03, 4.1341e-03,\n",
    "        3.9701e-03, 3.8546e-03, 3.8368e-03, 3.6334e-03, 3.4932e-03, 3.5462e-03,\n",
    "        3.3290e-03, 3.1136e-03, 3.0344e-03, 3.0523e-03, 3.0798e-03, 2.8599e-03,\n",
    "        2.9140e-03, 2.5425e-03, 2.7643e-03, 2.6815e-03, 2.6966e-03, 2.6264e-03,\n",
    "        2.5839e-03, 2.2999e-03, 2.4701e-03, 2.3590e-03, 2.2112e-03, 2.2771e-03,\n",
    "        2.1826e-03, 2.0318e-03, 1.9751e-03, 1.8369e-03, 1.7660e-03, 1.6328e-03,\n",
    "        1.5771e-03, 1.6097e-03, 1.5245e-03, 1.5191e-03, 1.4376e-03, 1.4123e-03,\n",
    "        1.4145e-03, 1.1608e-03, 1.1681e-03, 1.2211e-03, 1.1449e-03, 1.1249e-03,\n",
    "        1.0067e-03, 9.1852e-04, 9.2093e-04, 8.5299e-04, 8.5505e-04, 8.1404e-04,\n",
    "        8.1366e-04, 9.1140e-04, 7.3335e-04, 6.7294e-04, 6.6730e-04, 7.5947e-04,\n",
    "        7.1015e-04, 6.4234e-04, 6.2060e-04, 5.4270e-04, 4.9665e-04, 5.1080e-04,\n",
    "        5.1578e-04, 8.4158e-04, 5.0561e-04, 4.6750e-04, 3.7118e-04, 2.7763e-04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36412"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train[~df_train[\"path\"].isna()][\"path\"].unique()) + len(test_df_erc[~test_df_erc[\"path\"].isna()][\"path\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.mm_contrast import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_text = False\n",
    "pre_train_audio = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if pre_train_text:\n",
    "    train_ds = torch.utils.data.TensorDataset(torch.Tensor(list(range(len(df_train)))))\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=300, shuffle=True)\n",
    "\n",
    "    test_ds = torch.utils.data.TensorDataset(torch.Tensor(list(range(len(test_df_erc)))))\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=1024, shuffle=False)\n",
    "\n",
    "    MODEL_NAME = 'sentence-transformers/all-mpnet-base-v2'\n",
    "    text_encoder = TextEncoder(MODEL_NAME, max_len=MAX_LEN, extra_tokens=['[NAME]', '[RELIGION]', '[LAUGHTER]', '[BFR]', '[AFT]'])\n",
    "\n",
    "    PATH_TO_SAVE = f'text_encoder_pre_trained_{MODEL_NAME}'\n",
    "    !mkdir -p {PATH_TO_SAVE}\n",
    "    supcon_model = AudioTextContrastive(\n",
    "        text_encoder,\n",
    "        audio_encoder,\n",
    "        in_features_text=768,\n",
    "        in_features_audio=dim_embed, \n",
    "        hidden_size=768,\n",
    "        wide_proj=1024,\n",
    "        proj_size=128, \n",
    "        rate=0.1,\n",
    "    )\n",
    "\n",
    "    # Grid search best temperatures\n",
    "    # Try to only fine tune on evaluation datasets\n",
    "    #supcon_model.load_state_dict(torch.load(f'ESTAMOS_PERTO_AMIGO_ESTOU_AQUI_4_freezed_4_layer/pytorch_model_AudioTextCLIP_epoch_9.bin')['model'])\n",
    "\n",
    "    supcon_model.to(0)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    step = 0\n",
    "    e = 0\n",
    "    patience = 9999\n",
    "    early_stop_flag = 0\n",
    "    old_f1 = -float('inf')\n",
    "\n",
    "    param_optimizer = list(supcon_model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [{\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate':\n",
    "        0.1\n",
    "    }, {\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate':\n",
    "        0.0\n",
    "    }]\n",
    "\n",
    "    scheduler_epochs = 5\n",
    "    opt = torch.optim.AdamW(optimizer_grouped_parameters, lr=2e-5, betas=(0.9, 0.98), eps=1e-8)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor=0.5, end_factor=0.9, total_iters=10, last_epoch=- 1, verbose=False)\n",
    "    #scheduler = Scheduler(opt, 768, 600)\n",
    "\n",
    "    epochs = 9999\n",
    "\n",
    "    while e < epochs:\n",
    "        supcon_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        proj_val = []\n",
    "        targets_val = []\n",
    "\n",
    "        proj_train = []\n",
    "        targets_train = []\n",
    "\n",
    "        for i, batch_indices in enumerate(tqdm(train_loader, total=len(train_loader))):\n",
    "            if i == len(train_loader)-1:\n",
    "                continue\n",
    "            batch = df_train.iloc[batch_indices[0]]\n",
    "            batch = batch[~batch[\"text\"].isna()].reset_index(drop=True)\n",
    "\n",
    "            batch_lab_idx = batch[batch[\"label\"].notna()].index\n",
    "            sentences = batch[\"text\"].tolist()\n",
    "\n",
    "            y_text = torch.Tensor(lab_encoder.transform(batch.iloc[batch_lab_idx][\"label\"]))\n",
    "            y_text_senti = torch.Tensor(lab_encoder_senti.transform(batch[\"sentiment_label\"]))\n",
    "\n",
    "            # Augment Text Context\n",
    "            #for i_s, s in enumerate(sentences):\n",
    "            #    if \"[CTXE]\" in s.split(' '):\n",
    "            #        if np.random.rand() < 0.5:\n",
    "            #            sentences[i_s] = sentences[i_s].split(\"[CTXE]\")[1]\n",
    "\n",
    "            for k, s in enumerate(sentences):\n",
    "                if '[BFR]' not in s and '[AFT]' not in s:\n",
    "                    continue\n",
    "                p = np.random.rand()\n",
    "                if p < 0.25 and '[BFR]' in s:\n",
    "                    sentences[k] = sentences[k].split('[BFR]')[1]\n",
    "\n",
    "                p = np.random.rand()\n",
    "                if p < 0.25 and '[AFT]' in s:\n",
    "                    sentences[k] = sentences[k].split('[AFT]')[0]\n",
    "\n",
    "            target = y_text.long().cuda()\n",
    "            target_senti = y_text_senti.long().cuda()\n",
    "\n",
    "            x = [sentences, None, None]\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16) as autocast, torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "\n",
    "                out = supcon_model(x)\n",
    "\n",
    "                # Multimodal loss\n",
    "                out_x = out[\"x_text\"]\n",
    "                out_x_lab = out_x[batch_lab_idx]\n",
    "                out_x_wide = out[\"x_text_wide\"][batch_lab_idx]\n",
    "\n",
    "                loss = 0.8 * sup_contrastive_loss(out_x_lab, target, temperature=0.1) + 0.2 * sup_contrastive_loss(out_x, target_senti, temperature=0.1)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            #scheduler.step()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            proj_train.append(np.array(out_x_wide.detach().cpu()))\n",
    "            targets_train.append(np.array(target.cpu()))\n",
    "\n",
    "            del out_x\n",
    "            del out\n",
    "            del out_x_wide\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        scheduler.step()\n",
    "        proj_train = np.concatenate(proj_train, axis=0)\n",
    "        targets_train = np.concatenate(targets_train, axis=0)\n",
    "\n",
    "        clf = FaissKNeighbors(k=128)\n",
    "        clf.fit(proj_train, np.array(targets_train, dtype=int))\n",
    "\n",
    "        epoch_loss = epoch_loss/len(train_loader)\n",
    "        #supcon_model.eval()\n",
    "        preds = []\n",
    "        targets = []\n",
    "        css = 0.0\n",
    "        wide_audio = []\n",
    "\n",
    "        for i, batch_indices in enumerate(tqdm(test_loader, total=len(test_loader))):\n",
    "            with torch.no_grad():\n",
    "\n",
    "                multimodal_batch = test_df_erc.iloc[batch_indices[0]]\n",
    "\n",
    "                sentences = [str(t['text']) for _, t in multimodal_batch.iterrows()]\n",
    "\n",
    "                target = torch.Tensor(lab_encoder.transform(list(multimodal_batch[\"label\"])))\n",
    "\n",
    "                x = [sentences, None, None]\n",
    "                with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16) as autocast, torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "                    out = supcon_model(x)\n",
    "\n",
    "                # Multimodal loss\n",
    "                out_x_wide = out[\"x_text_wide\"]\n",
    "\n",
    "                wide = np.array(out_x_wide.cpu())\n",
    "                pred = clf.predict(wide)\n",
    "                preds.append(pred)\n",
    "\n",
    "                assert len(wide) == len(pred)\n",
    "\n",
    "                proj_val.append(wide)\n",
    "                targets_val.append(np.array(target.cpu()))\n",
    "                del out_x_wide\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        proj_val = np.concatenate(proj_val, axis=0)\n",
    "        targets_val = np.concatenate(targets_val, axis=0)\n",
    "\n",
    "        preds = np.array(np.concatenate(preds, axis=0))\n",
    "\n",
    "        general_f1 = f1_score(targets_val, preds, average='weighted')\n",
    "        general_acc = accuracy_score(targets_val, preds)\n",
    "\n",
    "        meld_idx = test_df_erc[test_df_erc[\"source\"] == \"meld\"].index\n",
    "        iemocap_idx = test_df_erc[test_df_erc[\"source\"] != \"meld\"].index\n",
    "\n",
    "        general_f1_iemocap = f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='weighted')\n",
    "        general_acc_iemocap = accuracy_score(targets_val[iemocap_idx], preds[iemocap_idx])\n",
    "\n",
    "        general_f1_meld = f1_score(targets_val[meld_idx], preds[meld_idx], average='weighted')\n",
    "        general_acc_meld = accuracy_score(targets_val[meld_idx], preds[meld_idx])\n",
    "\n",
    "        print(f'General - KNN F1: {general_f1} Acc: {general_acc}')\n",
    "        print(f'Iemocap - KNN F1: {general_f1_iemocap} Acc: {general_acc_iemocap}')\n",
    "        print(f'Meld - KNN F1: {general_f1_meld} Acc: {general_acc_meld}')\n",
    "        print(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "        print(f\"Meld - KNN F1 (macro): {f1_score(targets_val[meld_idx], preds[meld_idx], average='macro')}\")\n",
    "\n",
    "        try:\n",
    "            tsne = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=5).fit_transform(proj_val)\n",
    "\n",
    "            sns.scatterplot(x=tsne[:, 0], y=tsne[:, 1], hue=lab_encoder.inverse_transform(list(np.array(targets_val, dtype=int))) , palette='tab10')\n",
    "            plt.show()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(f'Epoch: {e + 1} - Train Loss: {epoch_loss}')\n",
    "        e += 1\n",
    "\n",
    "        #if e == scheduler_epochs: # Unfreeze text encoder\n",
    "        #    for i, (name, param) in enumerate(list(supcon_model.text_encoder.named_parameters())):\n",
    "        #        param.requires_grad = True\n",
    "\n",
    "        with open(f\"{PATH_TO_SAVE}/metrics_epoch_{e}.txt\", \"w\") as f:\n",
    "            f.write(f'General - KNN F1: {general_f1} Acc: {general_acc}')\n",
    "            f.write(f'Iemocap - KNN F1: {general_f1_iemocap} Acc: {general_acc_iemocap}')\n",
    "            f.write(f'Meld - KNN F1: {general_f1_meld} Acc: {general_acc_meld}')\n",
    "            f.write(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "            f.write(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "            f.write(f\"Meld - KNN F1 (macro): {f1_score(targets_val[meld_idx], preds[meld_idx], average='macro')}\")\n",
    "\n",
    "        checkpoint = {\"model\": supcon_model.state_dict(),\n",
    "                  \"optimizer\": opt.state_dict(),\n",
    "                  \"scaler\": scaler.state_dict()}\n",
    "        torch.save(checkpoint, f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_{e}.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_train_text:\n",
    "    supcon_model = AudioTextContrastive(\n",
    "        text_encoder,\n",
    "        audio_encoder,\n",
    "        in_features_text=768,\n",
    "        in_features_audio=dim_embed, \n",
    "        hidden_size=768,\n",
    "        wide_proj=1024,\n",
    "        proj_size=128, \n",
    "        rate=0.2,\n",
    "    )\n",
    "    supcon_model.load_state_dict(torch.load(f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_17.bin')['model'])\n",
    "    torch.save(supcon_model.text_encoder.state_dict(), f'{PATH_TO_SAVE}/dabest_text_encoder.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio PreTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_train_audio:\n",
    "    train_ds = torch.utils.data.TensorDataset(torch.Tensor(list(range(len(df_train[df_train[\"path\"].notna()])))))\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=768, shuffle=True)\n",
    "\n",
    "    test_ds = torch.utils.data.TensorDataset(torch.Tensor(list(range(len(test_df_erc)))))\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=1024, shuffle=False)\n",
    "\n",
    "    PATH_TO_SAVE = 'audio_encoder_pre_trained_1_layer'\n",
    "    !mkdir -p {PATH_TO_SAVE}\n",
    "    supcon_model = AudioTextContrastive(\n",
    "        None,\n",
    "        audio_encoder,\n",
    "        in_features_text=384,\n",
    "        in_features_audio=dim_embed, \n",
    "        hidden_size=768,\n",
    "        wide_proj=1024,\n",
    "        proj_size=128, \n",
    "        rate=0.1,\n",
    "    )\n",
    "\n",
    "    # Grid search best temperatures\n",
    "    # Try to only fine tune on evaluation datasets\n",
    "\n",
    "    supcon_model.to(0)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    step = 0\n",
    "    e = 0\n",
    "    patience = 9999\n",
    "    early_stop_flag = 0\n",
    "    old_f1 = -float('inf')\n",
    "\n",
    "    param_optimizer = list(supcon_model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [{\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate':\n",
    "        0.1\n",
    "    }, {\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate':\n",
    "        0.0\n",
    "    }]\n",
    "\n",
    "    scheduler_epochs = 5\n",
    "    opt = torch.optim.AdamW(optimizer_grouped_parameters, lr=0, betas=(0.9, 0.98), eps=1e-8)\n",
    "    #scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor=0.5, end_factor=0.9, total_iters=10, last_epoch=- 1, verbose=False)\n",
    "    scheduler = Scheduler(opt, dim_embed, 600)\n",
    "    #for i in range(51 * 177):\n",
    "    #    scheduler.step()\n",
    "    \n",
    "    #checkpoint = {\"model\": supcon_model.state_dict(),\n",
    "    #          \"optimizer\": opt.state_dict(),\n",
    "    #          \"scaler\": scaler.state_dict()}\n",
    "    #supcon_model.load_state_dict(torch.load(f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_51.bin')['model'])\n",
    "    #opt.load_state_dict(torch.load(f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_51.bin')['optimizer'])\n",
    "    #scaler.load_state_dict(torch.load(f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_51.bin')['scaler'])\n",
    "    \n",
    "    epochs = 9999\n",
    "\n",
    "    while e < epochs:\n",
    "        supcon_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        proj_val = []\n",
    "        targets_val = []\n",
    "\n",
    "        proj_train = []\n",
    "        targets_train = []\n",
    "\n",
    "        for i, batch_indices in enumerate(tqdm(train_loader, total=len(train_loader))):\n",
    "            if i == len(train_loader)-1:\n",
    "                continue\n",
    "            batch = df_train[df_train[\"path\"].notna()].reset_index(drop=True).iloc[batch_indices[0]]\n",
    "            \n",
    "            only_audio = batch[batch[\"path\"].notna()].reset_index(drop=True)\n",
    "            only_audio_lab_idx = only_audio[only_audio[\"label\"].notna()].index\n",
    "            \n",
    "            audio_paths = only_audio[\"path\"].tolist()\n",
    "            \n",
    "            mfccs, att = audio_tokenizer.batch_tokenize(audio_paths)\n",
    "\n",
    "            audio_input = {\n",
    "                \"features\": mfccs.float().to(0),\n",
    "                \"attn_masks\": att.float().to(0),\n",
    "            }\n",
    "\n",
    "            y_audio = torch.Tensor(lab_encoder.transform(only_audio.iloc[only_audio_lab_idx][\"label\"]))\n",
    "            y_audio_senti = torch.Tensor(lab_encoder_senti.transform(only_audio[\"sentiment_label\"]))\n",
    "\n",
    "            target = y_audio.long().cuda()\n",
    "            target_senti = y_audio_senti.long().cuda()\n",
    "\n",
    "            x = [None, audio_input, None]\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16) as autocast, torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "\n",
    "                out = supcon_model(x)\n",
    "\n",
    "                # Multimodal loss\n",
    "                out_x = out[\"x_audio\"]\n",
    "                out_x_lab = out_x[only_audio_lab_idx]\n",
    "                out_x_wide = out[\"x_audio_wide\"][only_audio_lab_idx]\n",
    "\n",
    "                loss = 0.8 * sup_contrastive_loss(out_x_lab, target, temperature=0.1) + 0.2 * sup_contrastive_loss(out_x, target_senti, temperature=0.1)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            proj_train.append(np.array(out_x_wide.detach().cpu()))\n",
    "            targets_train.append(np.array(target.cpu()))\n",
    "\n",
    "            del out_x\n",
    "            del out\n",
    "            del out_x_wide\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        proj_train = np.concatenate(proj_train, axis=0)\n",
    "        targets_train = np.concatenate(targets_train, axis=0)\n",
    "\n",
    "        clf = FaissKNeighbors(k=128)\n",
    "        clf.fit(proj_train, np.array(targets_train, dtype=int))\n",
    "\n",
    "        epoch_loss = epoch_loss/len(train_loader)\n",
    "        #supcon_model.eval()\n",
    "        preds = []\n",
    "        targets = []\n",
    "\n",
    "        for i, batch_indices in enumerate(tqdm(test_loader, total=len(test_loader))):\n",
    "            with torch.no_grad():\n",
    "\n",
    "                multimodal_batch = test_df_erc.iloc[batch_indices[0]]\n",
    "\n",
    "                audio_path_mult = [str(t['path']) for _, t in multimodal_batch.iterrows()]\n",
    "                mfccs_mult, att_mult = audio_tokenizer.batch_tokenize(audio_path_mult)\n",
    "\n",
    "                audio_input = {\"features\": mfccs_mult.float().to(0), \"attn_masks\": att_mult.float().to(0)}\n",
    "\n",
    "                target = torch.Tensor(lab_encoder.transform(list(multimodal_batch[\"label\"])))\n",
    "\n",
    "                x = [None, audio_input, None]\n",
    "                with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16) as autocast, torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "                    out = supcon_model(x)\n",
    "\n",
    "                # Multimodal loss\n",
    "                out_x_wide = out[\"x_audio_wide\"]\n",
    "\n",
    "                wide = np.array(out_x_wide.cpu())\n",
    "                pred = clf.predict(wide)\n",
    "                preds.append(pred)\n",
    "\n",
    "                assert len(wide) == len(pred)\n",
    "\n",
    "                proj_val.append(wide)\n",
    "                targets_val.append(np.array(target.cpu()))\n",
    "                del out_x_wide\n",
    "                del out\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        proj_val = np.concatenate(proj_val, axis=0)\n",
    "        targets_val = np.concatenate(targets_val, axis=0)\n",
    "\n",
    "        preds = np.array(np.concatenate(preds, axis=0))\n",
    "\n",
    "        general_f1 = f1_score(targets_val, preds, average='weighted')\n",
    "        general_acc = accuracy_score(targets_val, preds)\n",
    "\n",
    "        meld_idx = test_df_erc[test_df_erc[\"source\"] == \"meld\"].index\n",
    "        iemocap_idx = test_df_erc[test_df_erc[\"source\"] != \"meld\"].index\n",
    "\n",
    "        general_f1_iemocap = f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='weighted')\n",
    "        general_acc_iemocap = accuracy_score(targets_val[iemocap_idx], preds[iemocap_idx])\n",
    "\n",
    "        general_f1_meld = f1_score(targets_val[meld_idx], preds[meld_idx], average='weighted')\n",
    "        general_acc_meld = accuracy_score(targets_val[meld_idx], preds[meld_idx])\n",
    "\n",
    "        print(f'General - KNN F1: {general_f1} Acc: {general_acc}')\n",
    "        print(f'Iemocap - KNN F1: {general_f1_iemocap} Acc: {general_acc_iemocap}')\n",
    "        print(f'Meld - KNN F1: {general_f1_meld} Acc: {general_acc_meld}')\n",
    "        print(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "        print(f\"Meld - KNN F1 (macro): {f1_score(targets_val[meld_idx], preds[meld_idx], average='macro')}\")\n",
    "\n",
    "        try:\n",
    "            tsne = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=5).fit_transform(proj_val)\n",
    "\n",
    "            sns.scatterplot(x=tsne[:, 0], y=tsne[:, 1], hue=lab_encoder.inverse_transform(list(np.array(targets_val, dtype=int))) , palette='tab10')\n",
    "            plt.show()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(f'Epoch: {e + 1} - Train Loss: {epoch_loss}')\n",
    "        e += 1\n",
    "\n",
    "        #if e == scheduler_epochs: # Unfreeze text encoder\n",
    "        #    for i, (name, param) in enumerate(list(supcon_model.text_encoder.named_parameters())):\n",
    "        #        param.requires_grad = True\n",
    "\n",
    "        with open(f\"{PATH_TO_SAVE}/metrics_epoch_{e}.txt\", \"w\") as f:\n",
    "            f.write(f'General - KNN F1: {general_f1} Acc: {general_acc}')\n",
    "            f.write(f'Iemocap - KNN F1: {general_f1_iemocap} Acc: {general_acc_iemocap}')\n",
    "            f.write(f'Meld - KNN F1: {general_f1_meld} Acc: {general_acc_meld}')\n",
    "            f.write(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "            f.write(f\"Meld - KNN F1 (macro): {f1_score(targets_val[meld_idx], preds[meld_idx], average='macro')}\")\n",
    "\n",
    "        checkpoint = {\"model\": supcon_model.state_dict(),\n",
    "                  \"optimizer\": opt.state_dict(),\n",
    "                  \"scaler\": scaler.state_dict()}\n",
    "        torch.save(checkpoint, f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_{e}.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_train_audio:\n",
    "    supcon_model = AudioTextContrastive(\n",
    "        None,\n",
    "        audio_encoder,\n",
    "        in_features_text=384,\n",
    "        in_features_audio=dim_embed, \n",
    "        hidden_size=768,\n",
    "        wide_proj=1024,\n",
    "        proj_size=128, \n",
    "        rate=0.1,\n",
    "    )\n",
    "    supcon_model.load_state_dict(torch.load(f'audio_encoder_pre_trained_1_layer/pytorch_model_AudioTextCLIP_epoch_50.bin')['model'])\n",
    "    torch.save(supcon_model.audio_encoder.state_dict(), f'audio_encoder_pre_trained_1_layer/dabest_text_encoder.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_embed = 768\n",
    "N_VECTORS = 512\n",
    "MAX_LEN = 256\n",
    "\n",
    "audio_encoder = AudioEncoderMFCCHU(\n",
    "    N_VECTORS, \n",
    "    emb_dim=dim_embed, \n",
    "    n_layers=1, \n",
    "    max_length=MAX_LEN, \n",
    "    nheads=12,\n",
    "    dropout=0.1\n",
    ")\n",
    "audio_encoder.load_state_dict(torch.load(f'audio_encoder_pre_trained_1_layer/dabest_text_encoder.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'sentence-transformers/all-mpnet-base-v2'\n",
    "text_encoder = TextEncoder(MODEL_NAME, max_len=128, extra_tokens=['[NAME]', '[RELIGION]', '[LAUGHTER]', '[BFR]', '[AFT]'])\n",
    "text_encoder.load_state_dict(torch.load(f'text_encoder_pre_trained_{MODEL_NAME}/dabest_text_encoder.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in text_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in text_encoder.encoder.encoder.layer[11].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in text_encoder.encoder.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in audio_encoder.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5341a0d3bcaa4f44a3bc1673411b8135",
      "3fad1ce87a9f4b1baad4c056bd76d0ad",
      "3f40ded8f3884d468803b5cbb92d04af",
      "b272914175c14c5494bbd466ced2c24c",
      "7952be014e164b07ab81898a97fbc331",
      "98b25709d1f34983bf771a1bbd3dae3d",
      "bcfbcdafd7dd4d77a26037458e909fe5",
      "b47e5878d64c40519b6cb51321b90f62",
      "ef30cb62a33341cfa92780794e578fa8",
      "7506d573de6c4844bbf5f4af7947424b",
      "178de3d498054417b5f3661675d2deff",
      "ef6d4a9a190c411198829adc42a4e3c5",
      "ef74f18be5a940ba8696edb399e3b6f7",
      "87ef10ff662a4ea0994296b0c8577c3d",
      "104351e0f60c4dceacc51617d69cdef2",
      "b9b51ab0d78545739a420b73e0231b1d",
      "765d7438bce044758c9b1b818ede9ac4",
      "89cfc81fe5464ee9abb0a9a1a1b9d141",
      "9ca460fa5f584d9c88875eeb30eac76a",
      "b288324ff1fb4eeeb359d44cb1a40d12",
      "8d800f0793034ec29c37ac6e35ab3375",
      "5c5460fe4d344d9aaa3e87e41ca08164",
      "77d8310b1be34cf594a4731b9845e2a2",
      "862bfc472db84bfc8f031fd3a76e9809",
      "381e15620779478db7fcf1bd2d124c1b",
      "ea5c189c9660499f844a6fe3c90c59bf",
      "0b478c1f483e4fccbb6f56f002234dea",
      "d0fe5abc20594822bba649da177c106b",
      "70b8347a3a2c45b2b78a0117ec52e7ae",
      "9bf3f371933f4d328efa23edc61f9f46",
      "ffeda0d9845d4610aa25c47c14ad90f1",
      "671767bc077146a1aeed5607c971d138",
      "cf773a5a5a7c43d58957c19654160f6f",
      "7bd6fbe38ada40d5a18dcfa021326ea5",
      "9fbb36b544104cf2be8d7a6aa7cf28e1",
      "6b8ec460c2694c0ab4ed319f3d11e119",
      "93068874e3c3415bb750db3439d9cf6a",
      "bd3ced1d62224f7185d14373ad07cdff",
      "74dfc96b83f34e3c8403c192f423a6e3",
      "85f4be5ebdc94c7e8001a083a7c40154",
      "b6eba96636d54bbbbb87665595f9d96d",
      "c9532f4e341a4503abe2affac1f8e88e",
      "147da8015a5744b293df28397d0cb08c",
      "fa17642f8dcd425e87a7ea27c7782afd",
      "a41e0d7fd35c44bd80808903ea66cb61",
      "91c7531f525b4662844c113817a5bd10",
      "0b1501f7bf4a4b509267687b71bca3bb",
      "d860f362d07041228fb279ba07a48a75",
      "d135bd21ef514eeb95d91f8629bf7688",
      "563e4f1cc475402080aa71949a012f49",
      "ba6d485b3d364808894dc2336d9fd147",
      "c4dbc238f1304ecba571deabd74ff630",
      "154effefd76744f1847a4e90cd50adbe",
      "0f4366c0c2f74505b5268165f3ff15b5",
      "2ec467cae94e4f8fa22bc3d2bc563e85",
      "d6395a6be7334dc4a656a62fea25df3c",
      "b3df00cb8ab94fcf8b435765b8a9133b",
      "39e75864886e4a6c8ca47a53375d1e55",
      "bc1c88900f37416fa8ebec58ec0e8ff3",
      "9adf9f212e5945b58ff185047565bcf3",
      "6d00b5d46c58434cb2dedd09f975e504",
      "0e92d24aa67a4463843f09da7d592c94",
      "579642ddd5bf47e2861f1c7ae034f2a0",
      "a8f4bfce2b534d7b9a302ecb6986609d",
      "cbdc5f2631d94d399c00033043711360",
      "b6b140015ed746968a3f7bd4210ee5c5"
     ]
    },
    "id": "tton9xWfMTRv",
    "outputId": "1bbb0c70-8280-4c75-861a-69204da8f2ed",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████▌                               | 24/89 [01:00<02:34,  2.38s/it]"
     ]
    }
   ],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(torch.Tensor(list(range(len(df_train)))))\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
    "\n",
    "test_ds = torch.utils.data.TensorDataset(torch.Tensor(list(range(len(test_df_erc)))))\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=1024, shuffle=False)\n",
    "\n",
    "PATH_TO_SAVE = 'ESTAMOS_PERTO_AMIGO_ESTOU_AQUI_4_freezed_11'\n",
    "!mkdir -p {PATH_TO_SAVE}\n",
    "supcon_model = AudioTextContrastive(\n",
    "    text_encoder,\n",
    "    audio_encoder,\n",
    "    in_features_text=768,\n",
    "    in_features_audio=dim_embed, \n",
    "    hidden_size=768,\n",
    "    wide_proj=1024,\n",
    "    proj_size=128, \n",
    "    rate=0.1,\n",
    ")\n",
    "\n",
    "# Grid search best temperatures\n",
    "# Try to only fine tune on evaluation datasets\n",
    "#supcon_model.load_state_dict(torch.load(f'ESTAMOS_PERTO_AMIGO_ESTOU_AQUI_4_freezed_4_layer/pytorch_model_AudioTextCLIP_epoch_9.bin')['model'])\n",
    "\n",
    "supcon_model.to(0)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "step = 0\n",
    "e = 0\n",
    "patience = 9999\n",
    "early_stop_flag = 0\n",
    "old_f1 = -float('inf')\n",
    "\n",
    "param_optimizer = list(supcon_model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [{\n",
    "    'params':\n",
    "    [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate':\n",
    "    0.1\n",
    "}, {\n",
    "    'params':\n",
    "    [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate':\n",
    "    0.0\n",
    "}]\n",
    "\n",
    "scheduler_epochs = 5\n",
    "opt = torch.optim.AdamW(optimizer_grouped_parameters, lr=2e-5, betas=(0.9, 0.98), eps=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor=0.5, end_factor=0.9, total_iters=10, last_epoch=- 1, verbose=False)\n",
    "#scheduler = Scheduler(opt, 768, 600)\n",
    "\n",
    "epochs = 9999\n",
    "\n",
    "while e < epochs:\n",
    "    supcon_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    proj_val = []\n",
    "    targets_val = []\n",
    "\n",
    "    proj_train = []\n",
    "    targets_train = []\n",
    "\n",
    "    for i, batch_indices in enumerate(tqdm(train_loader, total=len(train_loader))):\n",
    "        if i == len(train_loader)-1:\n",
    "            continue\n",
    "        batch = df_train.iloc[batch_indices[0]]\n",
    "        only_text = batch[batch[\"path\"].isna()]\n",
    "        sentences = only_text[\"text\"].tolist()\n",
    "        y_text = torch.Tensor(lab_encoder.transform(only_text[\"label\"]))\n",
    "        y_text_senti = torch.Tensor(lab_encoder_senti.transform(only_text[\"sentiment_label\"]))\n",
    "        \n",
    "        only_audio = batch[batch[\"text\"].isna()]\n",
    "        audio_paths = only_audio[\"path\"].tolist()\n",
    "\n",
    "        mfccs, att = audio_tokenizer.batch_tokenize(audio_paths)\n",
    "\n",
    "        audio_input = {\n",
    "            \"features\": mfccs.float().to(0),\n",
    "            \"attn_masks\": att.float().to(0),\n",
    "        }\n",
    "\n",
    "        y_audio = torch.Tensor(lab_encoder.transform(only_audio[\"label\"]))\n",
    "        y_audio_senti = torch.Tensor(lab_encoder_senti.transform(only_audio[\"sentiment_label\"]))\n",
    "        \n",
    "        mult = batch[batch[\"text\"].notna()]\n",
    "        mult = mult[mult[\"path\"].notna()].reset_index(drop=True)\n",
    "        \n",
    "        mult_not_na_idx = mult[mult[\"label\"].notna()].index\n",
    "        #batch_not_na_idx = batch[batch[\"label\"].notna()].index\n",
    "        #mult_na_idx = mult[mult[\"label\"].isna()].index\n",
    "        \n",
    "        y_mult = torch.Tensor(lab_encoder.transform(mult.iloc[mult_not_na_idx][\"label\"]))\n",
    "        \n",
    "        y_mult_senti = torch.Tensor(lab_encoder_senti.transform(mult[\"sentiment_label\"]))\n",
    "        \n",
    "        audio_path_mult = [str(t['path']) for _, t in mult.iterrows()]\n",
    "        \n",
    "        mfccs_mult, att_mult = audio_tokenizer.batch_tokenize(audio_path_mult)\n",
    "        \n",
    "        # Augment Text Context\n",
    "        sentences_mult = [str(t['text']) for _, t in mult.iterrows()]\n",
    "        \n",
    "        multimodal = {'sentences': sentences_mult, \n",
    "                      'audio_input': {\"features\": mfccs_mult.float().to(0), \"attn_masks\": att_mult.float().to(0)}}\n",
    "        \n",
    "        target = torch.cat([y_text, y_audio, y_mult]).long().cuda()\n",
    "        target_senti = torch.cat([y_text_senti, y_audio_senti, y_mult_senti]).long().cuda()\n",
    "        \n",
    "        x = [sentences, audio_input, multimodal]\n",
    "        \n",
    "        if len(sentences) == 0:\n",
    "            x[0] = None\n",
    "        if len(audio_paths) == 0:\n",
    "            x[1] = None\n",
    "        if len(sentences_mult) == 0:\n",
    "            x[2] = None\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16) as autocast, torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "            \n",
    "            out = supcon_model(x)\n",
    "            \n",
    "            # Multimodal loss\n",
    "            if x[-1] is not None:\n",
    "                x_mult_text = out[\"x_mult_text\"]\n",
    "                x_mult_audio = out[\"x_mult_audio\"]\n",
    "                x_mult_text_norm = F.normalize(x_mult_text, dim=-1)\n",
    "                x_mult_audio_norm = F.normalize(x_mult_audio, dim=-1)\n",
    "                \n",
    "                #weights = torch.stack([torch.norm(x_mult_audio, dim=-1), torch.norm(x_mult_text, dim=-1)], dim=0).detach()\n",
    "                weights = torch.cat([torch.norm(x_mult_audio, dim=-1), torch.norm(x_mult_text, dim=-1)], dim=0).detach()\n",
    "                #weights = torch.ones_like(weights)\n",
    "                \n",
    "                # Augument modality\n",
    "                augs = random.choices(\n",
    "                    population=[0, 1, 2],\n",
    "                    weights=[0.8, 0.1, 0.1],\n",
    "                    k=len(x_mult_text)\n",
    "                )\n",
    "                \n",
    "                x_mult = torch.stack([F.normalize(x_mult_text + x_mult_audio, dim=-1), \n",
    "                                      x_mult_text_norm, \n",
    "                                     x_mult_audio_norm], dim=1)\n",
    "                \n",
    "                x_mult = x_mult[list(range(len(augs))), augs, :] \n",
    "                \n",
    "                x_mult_wide = F.normalize(out[\"x_mult_text_wide\"] + out[\"x_mult_audio_wide\"], dim=-1)\n",
    "                \n",
    "                # Add weighted contrastive loss\n",
    "                #x_mult_text = x_mult_text_norm.unsqueeze(dim=1)\n",
    "                #x_mult_audio = x_mult_audio_norm.unsqueeze(dim=1)\n",
    "                #mult = torch.cat([x_mult_text, x_mult_audio], dim=1)\n",
    "                \n",
    "                out_x, out_x_wide = None, None\n",
    "                \n",
    "                if x[0] is not None:\n",
    "                    if x[1] is not None:\n",
    "                        out_x = torch.cat([out[\"x_text\"], out[\"x_audio\"], x_mult], dim=0) #.unsqueeze(dim=1)\n",
    "                        out_x_lab = torch.cat([out[\"x_text\"], out[\"x_audio\"], x_mult[mult_not_na_idx]], dim=0) #.unsqueeze(dim=1)\n",
    "                        out_x_wide = torch.cat([out[\"x_text_wide\"], out[\"x_audio_wide\"], x_mult_wide[mult_not_na_idx]], dim=0)\n",
    "                    else:\n",
    "                        out_x = torch.cat([out[\"x_text\"], x_mult], dim=0) #.unsqueeze(dim=1)\n",
    "                        out_x_lab = torch.cat([out[\"x_text\"], x_mult[mult_not_na_idx]], dim=0) #.unsqueeze(dim=1)\n",
    "                        out_x_wide = torch.cat([out[\"x_text_wide\"], x_mult_wide[mult_not_na_idx]], dim=0)\n",
    "                elif x[1] is not None:\n",
    "                    out_x = torch.cat([out[\"x_audio\"], x_mult], dim=0) #.unsqueeze(dim=1)\n",
    "                    out_x_lab = torch.cat([out[\"x_audio\"], x_mult[mult_not_na_idx]], dim=0) #.unsqueeze(dim=1)\n",
    "                    out_x_wide = torch.cat([out[\"x_audio_wide\"], x_mult_wide[mult_not_na_idx]], dim=0)\n",
    "                else:\n",
    "                    out_x = x_mult.unsqueeze(dim=1)\n",
    "                    out_x_lab = x_mult[mult_not_na_idx] #.unsqueeze(dim=1)\n",
    "                    out_x_wide = x_mult_wide[mult_not_na_idx]\n",
    "                \n",
    "                # fera ta\n",
    "                \n",
    "                loss = 0.8 * (0.9 * sup_contrastive_loss(out_x_lab, target, temperature=0.1) + 0.1 * sup_contrastive_loss(out_x, target_senti, temperature=0.1)) \\\n",
    "                        + 0.2 * unsupervised_contrastive_loss(x_mult_text_norm, x_mult_audio_norm, temperature=0.1, weights=weights)\n",
    "                #loss = 0.5 * (0.5 * supcon_loss(out_x_lab, labels=target) + 0.5 * supcon_loss_senti(out_x, labels=target_senti)) + 0.5 * supcon_loss_intra(mult, weights=weights) \n",
    "            else:\n",
    "                if x[0] is not None:\n",
    "                    if x[1] is not None:\n",
    "                        out_x = torch.cat([out[\"x_text\"], out[\"x_audio\"]], dim=0).unsqueeze(dim=1)\n",
    "                        out_x_wide = torch.cat([out[\"x_text_wide\"], out[\"x_audio_wide\"]], dim=0)\n",
    "                    else:\n",
    "                        out_x = out[\"x_text\"]\n",
    "                        out_x_wide = out[\"x_text_wide\"]\n",
    "                else:\n",
    "                    if x[1] is not None:\n",
    "                        out_x = out[\"x_audio\"]\n",
    "                        out_x_wide = out[\"x_audio_wide\"]\n",
    "                    else:\n",
    "                        raise Exception(\"Nothing to work :()\")\n",
    "                        \n",
    "                loss = 0.8 * sup_contrastive_loss(out_x_lab, target, temperature=0.1) + 0.2 * sup_contrastive_loss(out_x, target_senti, temperature=0.1) #+ 0.8 * unsupervised_contrastive_loss(x_mult_text_norm, x_mult_audio_norm, temperature=0.8, weights=None)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(opt)\n",
    "\n",
    "        #torch.nn.utils.clip_grad_norm_(supcon_model.parameters(), 30.0)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        #scheduler.step()\n",
    "        \n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        proj_train.append(np.array(out_x_wide.detach().cpu()))\n",
    "        targets_train.append(np.array(target.cpu()))\n",
    "\n",
    "        del out_x\n",
    "        del x_mult\n",
    "        del out_x_wide\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    scheduler.step()\n",
    "    proj_train = np.concatenate(proj_train, axis=0)\n",
    "    targets_train = np.concatenate(targets_train, axis=0)\n",
    "    \n",
    "    clf = FaissKNeighbors(k=128)\n",
    "    clf.fit(proj_train, np.array(targets_train, dtype=int))\n",
    "\n",
    "    epoch_loss = epoch_loss/len(train_loader)\n",
    "    #supcon_model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    css = 0.0\n",
    "    wide_audio = []\n",
    "    \n",
    "    for i, batch_indices in enumerate(tqdm(test_loader, total=len(test_loader))):\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            multimodal_batch = test_df_erc.iloc[batch_indices[0]]\n",
    "\n",
    "            audio_path_mult = [str(t['path']) for _, t in multimodal_batch.iterrows()]\n",
    "            mfccs_mult, att_mult = audio_tokenizer.batch_tokenize(audio_path_mult)\n",
    "\n",
    "            sentences_mult = [str(t['text']) for _, t in multimodal_batch.iterrows()]\n",
    "\n",
    "            multimodal = {'sentences': sentences_mult, \n",
    "                          'audio_input': {\"features\": mfccs_mult.float().to(0), \"attn_masks\": att_mult.float().to(0)}}\n",
    "        \n",
    "            target = torch.Tensor(lab_encoder.transform(list(multimodal_batch[\"label\"])))\n",
    "\n",
    "            x = [None, None, multimodal]\n",
    "            with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16) as autocast, torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "                out = supcon_model(x)\n",
    "            \n",
    "            # Multimodal loss\n",
    "            out_x_wide = F.normalize(out[\"x_mult_text_wide\"] + out[\"x_mult_audio_wide\"], dim=-1)\n",
    "            \n",
    "            cs = F.cosine_similarity(F.normalize(out[\"x_mult_text_wide\"], dim=-1), F.normalize(out[\"x_mult_audio_wide\"], dim=-1))\n",
    "\n",
    "            wide = np.array(out_x_wide.cpu())\n",
    "            wide_audio.append(np.array(F.normalize(out[\"x_mult_audio_wide\"], dim=-1).cpu()))\n",
    "            pred = clf.predict(wide)\n",
    "            preds.append(pred)\n",
    "\n",
    "            assert len(wide) == len(pred)\n",
    "\n",
    "            proj_val.append(wide)\n",
    "            targets_val.append(np.array(target.cpu()))\n",
    "            css += np.sum(np.array(cs.cpu()))\n",
    "            del out_x_wide\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    proj_val = np.concatenate(proj_val, axis=0)\n",
    "    wide_audio = np.concatenate(wide_audio, axis=0)\n",
    "    targets_val = np.concatenate(targets_val, axis=0)\n",
    "    \n",
    "    preds = np.array(np.concatenate(preds, axis=0))\n",
    "    \n",
    "    css = css / len(test_df_erc)\n",
    "\n",
    "    general_f1 = f1_score(targets_val, preds, average='weighted')\n",
    "    general_acc = accuracy_score(targets_val, preds)\n",
    "    \n",
    "    print(f'Cosine Similarity between mods: {css}')\n",
    "    \n",
    "    meld_idx = test_df_erc[test_df_erc[\"source\"] == \"meld\"].index\n",
    "    iemocap_idx = test_df_erc[test_df_erc[\"source\"] != \"meld\"].index\n",
    "    \n",
    "    general_f1_iemocap = f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='weighted')\n",
    "    general_f1_iemocap_audio = f1_score(targets_val[iemocap_idx], clf.predict(wide_audio)[iemocap_idx], average='weighted')\n",
    "    general_acc_iemocap = accuracy_score(targets_val[iemocap_idx], preds[iemocap_idx])\n",
    "    \n",
    "    general_f1_meld = f1_score(targets_val[meld_idx], preds[meld_idx], average='weighted')\n",
    "    general_f1_meld_audio = f1_score(targets_val[meld_idx], clf.predict(wide_audio)[meld_idx], average='weighted')\n",
    "    general_acc_meld = accuracy_score(targets_val[meld_idx], preds[meld_idx])\n",
    "    \n",
    "    print(f'General - KNN F1: {general_f1} Acc: {general_acc}')\n",
    "    print(f'Iemocap - KNN F1: {general_f1_iemocap} Acc: {general_acc_iemocap}')\n",
    "    print(f'Iemocap - KNN F1 - Only Audio: {general_f1_iemocap_audio}')\n",
    "    print(f'Meld - KNN F1: {general_f1_meld} Acc: {general_acc_meld}')\n",
    "    print(f'Meld - KNN F1 - Only Audio: {general_f1_meld_audio}')\n",
    "    print(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "    print(f\"Meld - KNN F1 (macro): {f1_score(targets_val[meld_idx], preds[meld_idx], average='macro')}\")\n",
    "\n",
    "    try:\n",
    "        tsne = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=5).fit_transform(proj_val)\n",
    "\n",
    "        sns.scatterplot(x=tsne[:, 0], y=tsne[:, 1], hue=lab_encoder.inverse_transform(list(np.array(targets_val, dtype=int))) , palette='tab10')\n",
    "        plt.show()\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(f'Epoch: {e + 1} - Train Loss: {epoch_loss}')\n",
    "    e += 1\n",
    "    \n",
    "    #if e == scheduler_epochs: # Unfreeze text encoder\n",
    "    #    for i, (name, param) in enumerate(list(supcon_model.text_encoder.named_parameters())):\n",
    "    #        param.requires_grad = True\n",
    "\n",
    "    with open(f\"{PATH_TO_SAVE}/metrics_epoch_{e}.txt\", \"w\") as f:\n",
    "        f.write(f'General - KNN F1: {general_f1} Acc: {general_acc}')\n",
    "        f.write(f'Iemocap - KNN F1: {general_f1_iemocap} Acc: {general_acc_iemocap}')\n",
    "        f.write(f'Meld - KNN F1: {general_f1_meld} Acc: {general_acc_meld}')\n",
    "        f.write(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "        \n",
    "        f.write(f'Iemocap - KNN F1 - Only Audio: {general_f1_iemocap_audio}')\n",
    "        f.write(f'Meld - KNN F1 - Only Audio: {general_f1_meld_audio}')\n",
    "        f.write(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "        \n",
    "        f.write(f\"Meld - KNN F1 (macro): {f1_score(targets_val[meld_idx], preds[meld_idx], average='macro')}\")\n",
    "        \n",
    "    checkpoint = {\"model\": supcon_model.state_dict(),\n",
    "              \"optimizer\": opt.state_dict(),\n",
    "              \"scaler\": scaler.state_dict()}\n",
    "    torch.save(checkpoint, f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_{e}.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cosine Similarity between mods: 0.6148036817116292\n",
    "General - KNN F1: 0.652949920693673 Acc: 0.6535964684497533\n",
    "Iemocap - KNN F1: 0.7621117618450867 Acc: 0.7558420628525383\n",
    "Iemocap - KNN F1 - Only Audio: 0.48286032752145575\n",
    "Meld - KNN F1: 0.6025222678926638 Acc: 0.6049808429118774\n",
    "Iemocap - KNN F1 (macro): 0.6085758686292261\n",
    "Meld - KNN F1 (macro): 0.41899567212117655\n",
    "\n",
    "Epoch: 31 - Train Loss: 6.175596459077136\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#pickle.dump(kmeans, open(\"./transformer_1_layer_repetindo/kmeans_200_clusters_curr.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0IJvvdYd_vC"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH_TO_SAVE = 'ESTAMOS_PERTO_AMIGO_ESTOU_AQUI_4_freezed_5_layer_pivoting_to_speech_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.load(f'pre_test_final_2/pytorch_model_AudioTextCLIP_epoch_35.bin')['model']\n",
    "#torch.load(f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_1.bin')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IU9dQmJ4-gU"
   },
   "outputs": [],
   "source": [
    "PATH_TO_SAVE = 'ESTAMOS_PERTO_AMIGO_ESTOU_AQUI_4_freezed_11'\n",
    "\n",
    "supcon_model = AudioTextContrastive(\n",
    "    text_encoder,\n",
    "    audio_encoder,\n",
    "    in_features_text=768,\n",
    "    in_features_audio=dim_embed, \n",
    "    hidden_size=768,\n",
    "    wide_proj=1024,\n",
    "    proj_size=128, \n",
    "    rate=0.2,\n",
    ").cuda()\n",
    "supcon_model.load_state_dict(torch.load(f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_23.bin')['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_n_params(supcon_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supcon_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FlMSn326Ws6"
   },
   "outputs": [],
   "source": [
    "supcon_model.train()\n",
    "test = supcon_model([[\"I Hate you, i believe you are shit!\", \"You are my best friend, love you!\"],None, None])\n",
    "torch.dot(F.normalize(test[\"x_text_wide\"][0, :], dim=-1), F.normalize(test[\"x_text_wide\"][1, :], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZTR2bjv6rwC"
   },
   "outputs": [],
   "source": [
    "test = supcon_model([[\"The best man ever, keep the good work!\", \"you are my best friend, love you!\"],None, None])\n",
    "torch.dot(F.normalize(test[\"x_text_wide\"][0, :], dim=-1), F.normalize(test[\"x_text_wide\"][1, :], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CozRdOGE7EB6"
   },
   "outputs": [],
   "source": [
    "test = supcon_model([[\"I Hate you, i believe you are shit!\", \"Fuck you, you should not be alive\"],None, None])\n",
    "torch.dot(F.normalize(test[\"x_text_wide\"][0, :], dim=-1), F.normalize(test[\"x_text_wide\"][1, :], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = supcon_model([[\"I love you, mate!\", \"Fuck you, you should not be alive\"],None, None])\n",
    "torch.dot(F.normalize(test[\"x_text_wide\"][0, :], dim=-1), F.normalize(test[\"x_text_wide\"][1, :], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supcon_model.train()\n",
    "with torch.no_grad():\n",
    "    m, a = audio_tokenizer.batch_tokenize([\"./audio/audio_emo/tess.woman.sad.100.wav\"])\n",
    "    audio_input = {\n",
    "        \"features\": m.to(0),\n",
    "        \"attn_masks\": a.to(0),\n",
    "    }\n",
    "    test = supcon_model([[\"I am very sad\"],audio_input, None])\n",
    "    print(torch.dot(F.normalize(test[\"x_text_wide\"][0, :], dim=-1), F.normalize(test[\"x_audio_wide\"][0, :], dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(test[\"x_text\"][0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(test[\"x_audio\"][0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supcon_model.train()\n",
    "supcon_model.training = False\n",
    "with torch.no_grad():\n",
    "    m, a = audio_tokenizer.batch_tokenize([\"./audio/audio_emo/tess.woman.sad.101.wav\"])\n",
    "    audio_input = {\n",
    "        \"features\": m.to(0),\n",
    "        \"attn_masks\": a.to(0),\n",
    "    }\n",
    "    test = supcon_model([[\"I love my girlfriend, but she died\"],audio_input, None])\n",
    "    print(torch.dot(test[\"x_text\"][0, :], test[\"x_audio\"][0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supcon_model.train()\n",
    "supcon_model.training = False\n",
    "dropout_modules = [module for module in supcon_model.modules() if isinstance(module,torch.nn.Dropout)]\n",
    "[module.eval() for module in dropout_modules]\n",
    "\n",
    "with torch.no_grad():\n",
    "    m, a = audio_tokenizer.batch_tokenize([\"./audio/audio_emo/tess.woman.sad.279.wav\"])\n",
    "    audio_input = {\n",
    "        \"features\": m.to(0),\n",
    "        \"attn_masks\": a.to(0),\n",
    "    }\n",
    "    test = supcon_model([[\"I am happy\"], audio_input, None])\n",
    "    print(torch.dot(F.normalize(test[\"x_text_wide\"][0, :], dim=-1), F.normalize(test[\"x_audio_wide\"][0, :], dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supcon_model.train()\n",
    "supcon_model.training = False\n",
    "dropout_modules = [module for module in supcon_model.modules() if isinstance(module,torch.nn.Dropout)]\n",
    "[module.eval() for module in dropout_modules]\n",
    "\n",
    "with torch.no_grad():\n",
    "    m, a = audio_tokenizer.batch_tokenize([\"./audio/audio_emo/tess.woman.sad.279.wav\"])\n",
    "    audio_input = {\n",
    "        \"features\": m.to(0),\n",
    "        \"attn_masks\": a.to(0),\n",
    "    }\n",
    "    test = supcon_model([[\"My dog was great, but he was also cute! Today he is dead\"], audio_input, None])\n",
    "    print(torch.dot(F.normalize(test[\"x_text\"][0, :], dim=-1), F.normalize(test[\"x_audio\"][0, :], dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supcon_model.train()\n",
    "supcon_model.training = False\n",
    "dropout_modules = [module for module in supcon_model.modules() if isinstance(module,torch.nn.Dropout)]\n",
    "[module.eval() for module in dropout_modules]\n",
    "\n",
    "with torch.no_grad():\n",
    "    m, a = audio_tokenizer.batch_tokenize([\"./audio/audio_emo/tess.woman.happy.50.wav\"])\n",
    "    audio_input = {\n",
    "        \"features\": m.to(0),\n",
    "        \"attn_masks\": a.to(0),\n",
    "    }\n",
    "    test = supcon_model([[\"I had a discussion with my mother\", \"I love my mother\"],audio_input, None])\n",
    "    print(torch.dot(test[\"x_text_wide\"][0, :], test[\"x_audio_wide\"][0, :]))\n",
    "    print(torch.dot(test[\"x_text_wide\"][1, :], test[\"x_audio_wide\"][0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    m, a = audio_tokenizer.batch_tokenize([\"./audio/audio_emo/tess.woman.happy.50.wav\"])\n",
    "    audio_input = {\n",
    "        \"features\": m.to(0),\n",
    "        \"attn_masks\": a.to(0),\n",
    "    }\n",
    "    test = supcon_model([[\"I just finished my PhD!!\", \"I finished my PhD, but I dont have a job\"],audio_input, None])\n",
    "    print(torch.dot(F.normalize(test[\"x_text_wide\"][0, :], dim=-1), F.normalize(test[\"x_audio_wide\"][0, :], dim=-1)))\n",
    "    print(torch.dot(F.normalize(test[\"x_text_wide\"][1, :], dim=-1), F.normalize(test[\"x_audio_wide\"][0, :], dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supcon_model.train()\n",
    "supcon_model.training = False\n",
    "dropout_modules = [module for module in supcon_model.modules() if isinstance(module,torch.nn.Dropout)]\n",
    "[module.eval() for module in dropout_modules]\n",
    "\n",
    "with torch.no_grad():\n",
    "    m, a = audio_tokenizer.batch_tokenize([\"./audio/audio_emo/tess.woman.happy.279.wav\", \"./audio/audio_emo/tess.woman.sad.59.wav\"])\n",
    "    audio_input = {\n",
    "        \"features\": m.to(0),\n",
    "        \"attn_masks\": a.to(0),\n",
    "    }\n",
    "    test = supcon_model([[\"I did not pass in the final exam, i will kill myself\"], audio_input, None])\n",
    "    print(torch.dot(F.normalize(test[\"x_audio_wide\"][0, :], dim=-1), F.normalize(test[\"x_audio_wide\"][1, :], dim=-1)))\n",
    "    print(torch.dot(F.normalize(test[\"x_audio_wide\"][0, :], dim=-1), F.normalize(test[\"x_text_wide\"][0, :], dim=-1)))\n",
    "    print(torch.dot(F.normalize(test[\"x_audio_wide\"][1, :], dim=-1), F.normalize(test[\"x_text_wide\"][0, :], dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        print(output)\n",
    "        activation[name] = output #.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "supcon_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        print(output)\n",
    "        print(output.shape)\n",
    "        activation[name] = output #.detach()\n",
    "    return hook\n",
    "\n",
    "supcon_model = AudioTextContrastive(\n",
    "    text_encoder,\n",
    "    audio_encoder,\n",
    "    in_features_text=768,\n",
    "    in_features_audio=dim_embed, \n",
    "    hidden_size=768,\n",
    "    wide_proj=1024,\n",
    "    proj_size=128, \n",
    "    freeze_text_enc=True,\n",
    "    freeze_audio_enc=False,\n",
    "    rate=0.2,\n",
    ").cuda()\n",
    "\n",
    "supcon_model.load_state_dict(torch.load(f'{PATH_TO_SAVE}/pytorch_model_AudioTextCLIP_epoch_16.bin')['model'])\n",
    "\n",
    "supcon_model.audio_proj.register_forward_hook(get_activation('audio_proj'))\n",
    "output = supcon_model([[\"I had a discussion with my mother\"],audio_input, None])\n",
    "activation['audio_proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"x_audio_wide\"][0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"x_audio\"][0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train[\"label\"] == \"sadness\"][\"path\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supcon_model.load_state_dict(torch.load('./pytorch_model_AudioTextCLIPvFinal_epoch_25_only_meld.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supcon_model.audio_encoder.clusterization_model = kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J92hem554uXS"
   },
   "outputs": [],
   "source": [
    "df_train_f =df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIKswbRmlFZV"
   },
   "outputs": [],
   "source": [
    "#df_dev_audio = pd.concat([df_meld_dev, test_audio], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Param: Select dataset for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meld_train_idx = train_df_erc[train_df_erc[\"path\"].apply(lambda x: True if \"MELD\" in x else False)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iemocap_train_idx = train_df_erc[train_df_erc[\"path\"].apply(lambda x: False if \"MELD\" in x else True)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_audio_repeated = pd.concat([df_train_audio, df_train_audio,df_train_audio,df_train_audio,df_train_audio,df_train_audio,df_train_audio, df_train_audio,df_train_audio,df_train_audio,df_train_audio,df_train_audio], axis=0).sample(frac=1).reset_index(drop=True)\n",
    "#test_audio_repeated = pd.concat([df_dev_audio, df_dev_audio,df_dev_audio,df_dev_audio,df_dev_audio,df_dev_audio], axis=0).sample(frac=1).reset_index(drop=True)\n",
    "#train_iemocap = train_df_erc.iloc[iemocap_train_idx].reset_index(drop=True)\n",
    "#train_iemocap = train_df_erc.iloc[meld_train_idx].reset_index(drop=True)\n",
    "train_ds = torch.utils.data.TensorDataset(torch.Tensor(list(range(len(train_df_erc)))))\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=1024, shuffle=False)\n",
    "\n",
    "test_ds = torch.utils.data.TensorDataset(torch.Tensor(list(range(len(test_df_erc)))))\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "supcon_model.train()\n",
    "\n",
    "proj_val = []\n",
    "targets_val = []\n",
    "\n",
    "proj_train = []\n",
    "targets_train = []\n",
    "\n",
    "for i, batch_indices in enumerate(tqdm(train_loader, total=len(train_loader))):\n",
    "    with torch.no_grad():\n",
    "        batch = train_df_erc.iloc[batch_indices[0]]\n",
    "        only_text = batch[batch[\"path\"].isna()]\n",
    "        sentences = only_text[\"text\"].tolist()\n",
    "        y_text = torch.Tensor(lab_encoder.transform(only_text[\"label\"]))\n",
    "\n",
    "        only_audio = batch[batch[\"text\"].isna()]\n",
    "        audio_paths = only_audio[\"path\"].tolist()\n",
    "        try:\n",
    "            mfccs, att = audio_tokenizer.batch_tokenize(audio_paths)\n",
    "\n",
    "            audio_input = {\n",
    "                \"features\": mfccs.to(0),\n",
    "                \"attn_masks\": att.to(0),\n",
    "            }\n",
    "        except:\n",
    "            audio_input = None\n",
    "\n",
    "        y_audio = torch.Tensor(lab_encoder.transform(only_audio[\"label\"]))\n",
    "\n",
    "        mult = batch[batch[\"text\"].notna()]\n",
    "        mult = mult[mult[\"path\"].notna()]\n",
    "        mult = mult[mult[\"label\"].notna()]\n",
    "        y_mult = torch.Tensor(lab_encoder.transform(mult[\"label\"]))\n",
    "\n",
    "        audio_path_mult = [str(t['path']) for _, t in mult.iterrows()]\n",
    "\n",
    "        mfccs_mult, att_mult = audio_tokenizer.batch_tokenize(audio_path_mult)\n",
    "\n",
    "        sentences_mult = [str(t['text']) for _, t in mult.iterrows()]\n",
    "\n",
    "        multimodal = {'sentences': sentences_mult, \n",
    "                      'audio_input': {\"features\": mfccs_mult.to(0), \"attn_masks\": att_mult.to(0)}}\n",
    "\n",
    "        target = torch.cat([y_text, y_audio, y_mult])\n",
    "\n",
    "        x = [sentences, audio_input, multimodal]\n",
    "\n",
    "        if len(sentences) == 0:\n",
    "            x[0] = None\n",
    "        if len(audio_paths) == 0:\n",
    "            x[1] = None\n",
    "        if len(sentences_mult) == 0:\n",
    "            x[2] = None\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16) as autocast, torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "\n",
    "            out = supcon_model(x)\n",
    "\n",
    "            # Multimodal loss\n",
    "            x_mult_wide = F.normalize(out[\"x_mult_text_wide\"] + out[\"x_mult_audio_wide\"], dim=-1)\n",
    "            #x_mult_wide = F.normalize(out[\"x_mult_audio_wide\"], dim=-1)\n",
    "\n",
    "        proj_train.append(np.array(x_mult_wide.detach().cpu()))\n",
    "        targets_train.append(np.array(target.cpu()))\n",
    "\n",
    "        del x_mult_wide\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "proj_train = np.concatenate(proj_train, axis=0)\n",
    "targets_train = np.concatenate(targets_train, axis=0)\n",
    "\n",
    "clf = FaissKNeighbors(k=128)\n",
    "clf.fit(proj_train, np.array(targets_train, dtype=int))\n",
    "\n",
    "preds = []\n",
    "targets = []\n",
    "css = 0.0\n",
    "\n",
    "for i, batch_indices in enumerate(tqdm(test_loader, total=len(test_loader))):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        multimodal_batch = test_df_erc.iloc[batch_indices[0]]\n",
    "\n",
    "        audio_path_mult = [str(t['path']) for _, t in multimodal_batch.iterrows()]\n",
    "        mfccs_mult, att_mult = audio_tokenizer.batch_tokenize(audio_path_mult)\n",
    "\n",
    "        sentences_mult = [str(t['text']) for _, t in multimodal_batch.iterrows()]\n",
    "\n",
    "        multimodal = {'sentences': sentences_mult, \n",
    "                      'audio_input': {\"features\": mfccs_mult.to(0), \"attn_masks\": att_mult.to(0)}}\n",
    "\n",
    "        target = torch.Tensor(lab_encoder.transform(list(multimodal_batch[\"label\"])))\n",
    "\n",
    "        x = [None, None, multimodal]\n",
    "        with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16) as autocast, torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "            out = supcon_model(x)\n",
    "\n",
    "            # Multimodal loss\n",
    "            out_x_wide = F.normalize(out[\"x_mult_text_wide\"] + out[\"x_mult_audio_wide\"], dim=-1)\n",
    "            #out_x_wide = F.normalize(out[\"x_mult_audio_wide\"], dim=-1)\n",
    "\n",
    "        cs = F.cosine_similarity(out[\"x_mult_text_wide\"], out[\"x_mult_audio_wide\"])\n",
    "\n",
    "        wide = np.array(out_x_wide.cpu())\n",
    "        pred = clf.predict(wide)\n",
    "        preds.append(pred)\n",
    "\n",
    "        assert len(wide) == len(pred)\n",
    "\n",
    "        proj_val.append(wide)\n",
    "        targets_val.append(np.array(target.cpu()))\n",
    "        css += np.sum(np.array(cs.cpu()))\n",
    "        del out_x_wide\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "proj_val = np.concatenate(proj_val, axis=0)\n",
    "targets_val = np.concatenate(targets_val, axis=0)\n",
    "\n",
    "preds = np.array(np.concatenate(preds, axis=0))\n",
    "\n",
    "css = css / len(test_df_erc)\n",
    "\n",
    "general_f1 = f1_score(targets_val, preds, average='weighted')\n",
    "general_acc = accuracy_score(targets_val, preds)\n",
    "\n",
    "print(f'Cosine Similarity between mods: {css}')\n",
    "\n",
    "meld_idx = test_df_erc[test_df_erc[\"source\"] == \"meld\"].index\n",
    "iemocap_idx = test_df_erc[test_df_erc[\"source\"] != \"meld\"].index\n",
    "\n",
    "general_f1_iemocap = f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='weighted')\n",
    "general_acc_iemocap = accuracy_score(targets_val[iemocap_idx], preds[iemocap_idx])\n",
    "\n",
    "general_f1_meld = f1_score(targets_val[meld_idx], preds[meld_idx], average='weighted')\n",
    "general_acc_meld = accuracy_score(targets_val[meld_idx], preds[meld_idx])\n",
    "\n",
    "print(f'General - KNN F1: {general_f1} Acc: {general_acc}')\n",
    "print(f'Iemocap - KNN F1: {general_f1_iemocap} Acc: {general_acc_iemocap}')\n",
    "print(f'Meld - KNN F1: {general_f1_meld} Acc: {general_acc_meld}')\n",
    "\n",
    "print(f\"Iemocap - KNN F1 (macro): {f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='macro')}\")\n",
    "print(f\"Meld - KNN F1 (macro): {f1_score(targets_val[meld_idx], preds[meld_idx], average='macro')}\")\n",
    "\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=5).fit_transform(proj_val)\n",
    "\n",
    "sns.scatterplot(x=tsne[:, 0], y=tsne[:, 1], hue=lab_encoder.inverse_transform(list(np.array(targets_val, dtype=int))) , palette='tab10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mean_test = proj_train[meld_train_idx].mean(axis=0)\n",
    "std_test = proj_train[meld_train_idx].std(axis=0)\n",
    "clf = FaissKNeighbors(k=128)\n",
    "clf.fit((proj_train[meld_train_idx]-mean_test)/std_test, np.array(targets_train[meld_train_idx], dtype=int))\n",
    "\n",
    "preds = clf.predict((proj_val-mean_test)/std_test)\n",
    "\n",
    "general_f1_meld = f1_score(targets_val[meld_idx], preds[meld_idx], average='weighted')\n",
    "general_acc_meld = accuracy_score(targets_val[meld_idx], preds[meld_idx])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(targets_val[meld_idx], preds[meld_idx], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(targets_val[iemocap_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(lab_encoder.inverse_transform(np.array(targets_val[iemocap_idx], dtype=int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iemocap_orig = pd.read_json(\"emotions.json\").reset_index(drop=False)\n",
    "df_iemocap_orig = pd.melt(df_iemocap_orig, id_vars=['index'], value_vars=['train', 'val', 'test']).dropna().drop(columns=[\"variable\"]).rename(columns={\"index\":\"id\", \"value\": \"orig_label\"}).reset_index(drop=True)\n",
    "df_iemocap_orig = df_iemocap_orig[df_iemocap_orig[\"orig_label\"].notna() & (df_iemocap_orig[\"orig_label\"] != \"undecided\")].reset_index(drop=True)\n",
    "df_iemocap_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_shit(x):\n",
    "    if \"MELD\" in x:\n",
    "        return None\n",
    "    x = x.replace(\"val/\", \"\")\n",
    "    x = x.replace(\"train/\", \"\")\n",
    "    x = x.replace(\"test/\", \"\")\n",
    "    l = len(\"/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/\")\n",
    "    return x[l:].replace(\".wav\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_erc_iemocap = train_df_erc[train_df_erc[\"path\"].apply(lambda x: True if \"IEMOCAP\" in x else False)]\n",
    "train_df_erc[\"id\"] = train_df_erc[\"path\"].apply(cleaning_shit)\n",
    "train_df_erc_iemocap = train_df_erc.dropna()\n",
    "train_df_erc_iemocap = train_df_erc_iemocap.merge(df_iemocap_orig, on=\"id\", how=\"inner\").dropna()\n",
    "train_df_erc_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iemocap_train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_erc[\"id\"] = test_df_erc[\"path\"].apply(lambda x: x[len('/home/vmachado/Documents/multimodal-datasets/IEMOCAP/raw-audios/test/'):].replace(\".wav\", \"\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_erc_iemocap = test_df_erc[test_df_erc[\"source\"] == \"iemocap\"].reset_index(drop=True)\n",
    "test_df_erc_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_erc_iemocap = test_df_erc_iemocap.merge(df_iemocap_orig, on=\"id\", how=\"inner\")\n",
    "test_df_erc_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lab = LabelEncoder().fit(train_df_erc_iemocap[\"orig_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_erc_iemocap[\"orig_label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_erc_iemocap[\"orig_label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_erc_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_erc_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels_train = new_lab.transform(train_df_erc_iemocap[\"orig_label\"])\n",
    "correct_labels_test = new_lab.transform(test_df_erc_iemocap[\"orig_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_erc[test_df_erc[\"source\"] == \"iemocap\"][\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mean_test = proj_train.mean(axis=0)\n",
    "std_test = proj_train.std(axis=0)\n",
    "\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(768,), learning_rate=\"invscaling\", solver=\"sgd\", max_iter=5000, validation_fraction=0.2, nesterovs_momentum=False)\n",
    "clf = LogisticRegression()\n",
    "clf.fit((proj_train-mean_test)/std_test, np.array(targets_train, dtype=int))\n",
    "\n",
    "preds = clf.predict((proj_val-mean_test)/std_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(targets_val[iemocap_idx], preds[iemocap_idx], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_f1_iemocap = f1_score(targets_val[iemocap_idx], preds[iemocap_idx], average='weighted')\n",
    "general_acc_iemocap = accuracy_score(targets_val[iemocap_idx], preds[iemocap_idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_f1_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_f1_meld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(targets_val[iemocap_idx], list(map(lambda x: x if x != 1 else 6, preds[iemocap_idx])), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b1501f7bf4a4b509267687b71bca3bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4dbc238f1304ecba571deabd74ff630",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_154effefd76744f1847a4e90cd50adbe",
      "value": 112
     }
    },
    "0b478c1f483e4fccbb6f56f002234dea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e92d24aa67a4463843f09da7d592c94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f4366c0c2f74505b5268165f3ff15b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "104351e0f60c4dceacc51617d69cdef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d800f0793034ec29c37ac6e35ab3375",
      "placeholder": "​",
      "style": "IPY_MODEL_5c5460fe4d344d9aaa3e87e41ca08164",
      "value": " 629/629 [00:00&lt;00:00, 47.2kB/s]"
     }
    },
    "147da8015a5744b293df28397d0cb08c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "154effefd76744f1847a4e90cd50adbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "178de3d498054417b5f3661675d2deff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ec467cae94e4f8fa22bc3d2bc563e85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "381e15620779478db7fcf1bd2d124c1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bf3f371933f4d328efa23edc61f9f46",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ffeda0d9845d4610aa25c47c14ad90f1",
      "value": 231508
     }
    },
    "39e75864886e4a6c8ca47a53375d1e55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_579642ddd5bf47e2861f1c7ae034f2a0",
      "max": 69583549,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8f4bfce2b534d7b9a302ecb6986609d",
      "value": 69583549
     }
    },
    "3f40ded8f3884d468803b5cbb92d04af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b47e5878d64c40519b6cb51321b90f62",
      "max": 314,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef30cb62a33341cfa92780794e578fa8",
      "value": 314
     }
    },
    "3fad1ce87a9f4b1baad4c056bd76d0ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98b25709d1f34983bf771a1bbd3dae3d",
      "placeholder": "​",
      "style": "IPY_MODEL_bcfbcdafd7dd4d77a26037458e909fe5",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "5341a0d3bcaa4f44a3bc1673411b8135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fad1ce87a9f4b1baad4c056bd76d0ad",
       "IPY_MODEL_3f40ded8f3884d468803b5cbb92d04af",
       "IPY_MODEL_b272914175c14c5494bbd466ced2c24c"
      ],
      "layout": "IPY_MODEL_7952be014e164b07ab81898a97fbc331"
     }
    },
    "563e4f1cc475402080aa71949a012f49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "579642ddd5bf47e2861f1c7ae034f2a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c5460fe4d344d9aaa3e87e41ca08164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "671767bc077146a1aeed5607c971d138": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b8ec460c2694c0ab4ed319f3d11e119": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6eba96636d54bbbbb87665595f9d96d",
      "max": 466248,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9532f4e341a4503abe2affac1f8e88e",
      "value": 466248
     }
    },
    "6d00b5d46c58434cb2dedd09f975e504": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70b8347a3a2c45b2b78a0117ec52e7ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74dfc96b83f34e3c8403c192f423a6e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7506d573de6c4844bbf5f4af7947424b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "765d7438bce044758c9b1b818ede9ac4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77d8310b1be34cf594a4731b9845e2a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_862bfc472db84bfc8f031fd3a76e9809",
       "IPY_MODEL_381e15620779478db7fcf1bd2d124c1b",
       "IPY_MODEL_ea5c189c9660499f844a6fe3c90c59bf"
      ],
      "layout": "IPY_MODEL_0b478c1f483e4fccbb6f56f002234dea"
     }
    },
    "7952be014e164b07ab81898a97fbc331": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bd6fbe38ada40d5a18dcfa021326ea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fbb36b544104cf2be8d7a6aa7cf28e1",
       "IPY_MODEL_6b8ec460c2694c0ab4ed319f3d11e119",
       "IPY_MODEL_93068874e3c3415bb750db3439d9cf6a"
      ],
      "layout": "IPY_MODEL_bd3ced1d62224f7185d14373ad07cdff"
     }
    },
    "85f4be5ebdc94c7e8001a083a7c40154": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "862bfc472db84bfc8f031fd3a76e9809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0fe5abc20594822bba649da177c106b",
      "placeholder": "​",
      "style": "IPY_MODEL_70b8347a3a2c45b2b78a0117ec52e7ae",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "87ef10ff662a4ea0994296b0c8577c3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ca460fa5f584d9c88875eeb30eac76a",
      "max": 629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b288324ff1fb4eeeb359d44cb1a40d12",
      "value": 629
     }
    },
    "89cfc81fe5464ee9abb0a9a1a1b9d141": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d800f0793034ec29c37ac6e35ab3375": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91c7531f525b4662844c113817a5bd10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_563e4f1cc475402080aa71949a012f49",
      "placeholder": "​",
      "style": "IPY_MODEL_ba6d485b3d364808894dc2336d9fd147",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "93068874e3c3415bb750db3439d9cf6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_147da8015a5744b293df28397d0cb08c",
      "placeholder": "​",
      "style": "IPY_MODEL_fa17642f8dcd425e87a7ea27c7782afd",
      "value": " 466k/466k [00:00&lt;00:00, 526kB/s]"
     }
    },
    "98b25709d1f34983bf771a1bbd3dae3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9adf9f212e5945b58ff185047565bcf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bf3f371933f4d328efa23edc61f9f46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ca460fa5f584d9c88875eeb30eac76a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fbb36b544104cf2be8d7a6aa7cf28e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74dfc96b83f34e3c8403c192f423a6e3",
      "placeholder": "​",
      "style": "IPY_MODEL_85f4be5ebdc94c7e8001a083a7c40154",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "a41e0d7fd35c44bd80808903ea66cb61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_91c7531f525b4662844c113817a5bd10",
       "IPY_MODEL_0b1501f7bf4a4b509267687b71bca3bb",
       "IPY_MODEL_d860f362d07041228fb279ba07a48a75"
      ],
      "layout": "IPY_MODEL_d135bd21ef514eeb95d91f8629bf7688"
     }
    },
    "a8f4bfce2b534d7b9a302ecb6986609d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b272914175c14c5494bbd466ced2c24c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7506d573de6c4844bbf5f4af7947424b",
      "placeholder": "​",
      "style": "IPY_MODEL_178de3d498054417b5f3661675d2deff",
      "value": " 314/314 [00:00&lt;00:00, 17.4kB/s]"
     }
    },
    "b288324ff1fb4eeeb359d44cb1a40d12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3df00cb8ab94fcf8b435765b8a9133b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d00b5d46c58434cb2dedd09f975e504",
      "placeholder": "​",
      "style": "IPY_MODEL_0e92d24aa67a4463843f09da7d592c94",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "b47e5878d64c40519b6cb51321b90f62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6b140015ed746968a3f7bd4210ee5c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6eba96636d54bbbbb87665595f9d96d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9b51ab0d78545739a420b73e0231b1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba6d485b3d364808894dc2336d9fd147": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc1c88900f37416fa8ebec58ec0e8ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbdc5f2631d94d399c00033043711360",
      "placeholder": "​",
      "style": "IPY_MODEL_b6b140015ed746968a3f7bd4210ee5c5",
      "value": " 69.6M/69.6M [00:00&lt;00:00, 165MB/s]"
     }
    },
    "bcfbcdafd7dd4d77a26037458e909fe5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd3ced1d62224f7185d14373ad07cdff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4dbc238f1304ecba571deabd74ff630": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9532f4e341a4503abe2affac1f8e88e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cbdc5f2631d94d399c00033043711360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf773a5a5a7c43d58957c19654160f6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0fe5abc20594822bba649da177c106b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d135bd21ef514eeb95d91f8629bf7688": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6395a6be7334dc4a656a62fea25df3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3df00cb8ab94fcf8b435765b8a9133b",
       "IPY_MODEL_39e75864886e4a6c8ca47a53375d1e55",
       "IPY_MODEL_bc1c88900f37416fa8ebec58ec0e8ff3"
      ],
      "layout": "IPY_MODEL_9adf9f212e5945b58ff185047565bcf3"
     }
    },
    "d860f362d07041228fb279ba07a48a75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f4366c0c2f74505b5268165f3ff15b5",
      "placeholder": "​",
      "style": "IPY_MODEL_2ec467cae94e4f8fa22bc3d2bc563e85",
      "value": " 112/112 [00:00&lt;00:00, 7.45kB/s]"
     }
    },
    "ea5c189c9660499f844a6fe3c90c59bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_671767bc077146a1aeed5607c971d138",
      "placeholder": "​",
      "style": "IPY_MODEL_cf773a5a5a7c43d58957c19654160f6f",
      "value": " 232k/232k [00:00&lt;00:00, 341kB/s]"
     }
    },
    "ef30cb62a33341cfa92780794e578fa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef6d4a9a190c411198829adc42a4e3c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef74f18be5a940ba8696edb399e3b6f7",
       "IPY_MODEL_87ef10ff662a4ea0994296b0c8577c3d",
       "IPY_MODEL_104351e0f60c4dceacc51617d69cdef2"
      ],
      "layout": "IPY_MODEL_b9b51ab0d78545739a420b73e0231b1d"
     }
    },
    "ef74f18be5a940ba8696edb399e3b6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_765d7438bce044758c9b1b818ede9ac4",
      "placeholder": "​",
      "style": "IPY_MODEL_89cfc81fe5464ee9abb0a9a1a1b9d141",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "fa17642f8dcd425e87a7ea27c7782afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffeda0d9845d4610aa25c47c14ad90f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
