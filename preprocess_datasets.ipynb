{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b1832681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"utility and helper functions / classes.\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "\n",
    "def make_MELD_IEMOCAP():\n",
    "\n",
    "    SEED = 42\n",
    "    ratios = {\"train\": 0.9, \"val\": 0.1, \"test\": 0}\n",
    "\n",
    "    assert sum(list(ratios.values())) == 1\n",
    "\n",
    "    utterance_ordered = {}\n",
    "\n",
    "    with open(f\"./MELD/utterance-ordered.json\", \"r\") as stream:\n",
    "        utterance_ordered[\"MELD\"] = json.load(stream)\n",
    "\n",
    "    with open(f\"./IEMOCAP/utterance-ordered.json\", \"r\") as stream:\n",
    "        utterance_ordered[\"IEMOCAP\"] = json.load(stream)\n",
    "\n",
    "    diaids_merged = []\n",
    "\n",
    "    for DATASET in [\"MELD\", \"IEMOCAP\"]:\n",
    "        for SPLIT in [\"train\", \"val\", \"test\"]:\n",
    "            diaids = list(utterance_ordered[DATASET][SPLIT].keys())\n",
    "            for diaid in diaids:\n",
    "                diaids_merged.append(f\"{DATASET}/{SPLIT}/{diaid}\")\n",
    "\n",
    "    random.seed(SEED)\n",
    "    random.shuffle(diaids_merged)\n",
    "\n",
    "    train_idx = int(len(diaids_merged) * ratios[\"train\"])\n",
    "    val_idx = int(len(diaids_merged) * (ratios[\"train\"] + ratios[\"val\"]))\n",
    "\n",
    "    diaids_train = diaids_merged[:train_idx]\n",
    "    diaids_val = diaids_merged[train_idx:val_idx]\n",
    "    diaids_test = diaids_merged[val_idx:]\n",
    "\n",
    "    assert len(diaids_merged) == (\n",
    "        len(diaids_train) + len(diaids_val) + len(diaids_test)\n",
    "    )\n",
    "\n",
    "    diaids_merged = {\"train\": diaids_train, \"val\": diaids_val, \"test\": diaids_test}\n",
    "\n",
    "    utterance_ordered_merged = {}\n",
    "\n",
    "    for SPLIT in [\"train\", \"val\", \"test\"]:\n",
    "        utterance_ordered_merged[SPLIT] = {}\n",
    "\n",
    "        for diaid in tqdm(diaids_merged[SPLIT]):\n",
    "\n",
    "            d_, s_, d__ = diaid.split(\"/\")\n",
    "            utterance_ordered_merged[SPLIT][diaid] = [\n",
    "                f\"{d_}/{s_}/{d__}/{uttid}\" for uttid in utterance_ordered[d_][s_][d__]\n",
    "            ]\n",
    "\n",
    "    assert len(\n",
    "        [\n",
    "            val___\n",
    "            for key, val in utterance_ordered.items()\n",
    "            for key_, val_ in val.items()\n",
    "            for key__, val__ in val_.items()\n",
    "            for val___ in val__\n",
    "        ]\n",
    "    ) == len(\n",
    "        [\n",
    "            val__\n",
    "            for key, val in utterance_ordered_merged.items()\n",
    "            for key_, val_ in val.items()\n",
    "            for val__ in val_\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(\"./utterance-ordered-MELD_IEMOCAP.json\", \"w\") as stream:\n",
    "        json.dump(utterance_ordered_merged, stream, indent=4)\n",
    "\n",
    "\n",
    "def get_num_classes(DATASET: str) -> int:\n",
    "    \"\"\"Get the number of classes to be classified by dataset.\"\"\"\n",
    "    if DATASET == \"MELD\":\n",
    "        NUM_CLASSES = 7\n",
    "    elif DATASET == \"IEMOCAP\":\n",
    "        NUM_CLASSES = 6\n",
    "    elif DATASET == \"MELD_IEMOCAP\":\n",
    "        NUM_CLASSES = 7\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return 7\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions) -> dict:\n",
    "    \"\"\"Return f1_weighted, f1_micro, and f1_macro scores.\"\"\"\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "    f1_weighted = f1_score(label_ids, preds, average=\"weighted\")\n",
    "    f1_micro = f1_score(label_ids, preds, average=\"micro\")\n",
    "    f1_macro = f1_score(label_ids, preds, average=\"macro\")\n",
    "\n",
    "    return {\"f1_weighted\": f1_weighted, \"f1_micro\": f1_micro, \"f1_macro\": f1_macro}\n",
    "\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"Set random seed to a fixed value.\n",
    "\n",
    "    Set everything to be deterministic\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def get_emotion2id(DATASET: str) -> Tuple[dict, dict]:\n",
    "    \"\"\"Get a dict that converts string class to numbers.\"\"\"\n",
    "    emotions = [\n",
    "        \"neutral\",\n",
    "        \"joy\",\n",
    "        #\"excited\",\n",
    "        \"surprise\",\n",
    "        \"anger\",\n",
    "        \"frustration\",\n",
    "        \"sadness\",\n",
    "        \"disgust\",\n",
    "        \"fear\",\n",
    "    ]\n",
    "        \n",
    "    emotion2id = {\n",
    "        \"neutral\": 0,\n",
    "        \"joy\": 1,\n",
    "        \"happiness\": 1,\n",
    "        \"excited\": 1,\n",
    "        \"surprise\": 2,\n",
    "        \"anger\": 3,\n",
    "        \"frustration\": 4,\n",
    "        \"sadness\": 5,\n",
    "        \"disgust\": 6,\n",
    "        \"fear\": 7,\n",
    "    }\n",
    "    id2emotion = {idx: emotion for idx, emotion in enumerate(emotions)}\n",
    "\n",
    "    return emotion2id, id2emotion\n",
    "\n",
    "\n",
    "class ErcTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        DATASET=\"MELD\",\n",
    "        SPLIT=\"train\",\n",
    "        speaker_mode=\"upper\",\n",
    "        num_past_utterances=0,\n",
    "        num_future_utterances=0,\n",
    "        model_checkpoint=\"roberta-base\",\n",
    "        ROOT_DIR=\"./\",\n",
    "        ONLY_UPTO=False,\n",
    "        SEED=0,\n",
    "    ):\n",
    "        \"\"\"Initialize emotion recognition in conversation text modality dataset class.\"\"\"\n",
    "\n",
    "        self.DATASET = DATASET\n",
    "        self.ROOT_DIR = ROOT_DIR\n",
    "        self.SPLIT = SPLIT\n",
    "        self.speaker_mode = speaker_mode\n",
    "        self.num_past_utterances = num_past_utterances\n",
    "        self.num_future_utterances = num_future_utterances\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.emotion2id, self.id2emotion = get_emotion2id(self.DATASET)\n",
    "        self.ONLY_UPTO = ONLY_UPTO\n",
    "        self.SEED = SEED\n",
    "\n",
    "        self._load_emotions()\n",
    "        self._load_utterance_ordered()\n",
    "        self._string2tokens()\n",
    "\n",
    "    def _load_emotions(self):\n",
    "        \"\"\"Load the supervised labels\"\"\"\n",
    "        if self.DATASET in [\"MELD\", \"IEMOCAP\"]:\n",
    "            with open(\n",
    "                os.path.join(self.ROOT_DIR, self.DATASET, \"emotions.json\"), \"r\"\n",
    "            ) as stream:\n",
    "                self.emotions = json.load(stream)[self.SPLIT]\n",
    "\n",
    "    def _load_utterance_ordered(self):\n",
    "        \"\"\"Load the ids of the utterances in order.\"\"\"\n",
    "        if self.DATASET in [\"MELD\", \"IEMOCAP\"]:\n",
    "            path = os.path.join(self.ROOT_DIR, self.DATASET, \"utterance-ordered.json\")\n",
    "        elif self.DATASET == \"MELD_IEMOCAP\":\n",
    "            path = \"./utterance-ordered-MELD_IEMOCAP.json\"\n",
    "\n",
    "        with open(path, \"r\") as stream:\n",
    "            self.utterance_ordered = json.load(stream)[self.SPLIT]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_)\n",
    "\n",
    "    def _load_utterance_speaker_emotion(self, uttid, speaker_mode) -> dict:\n",
    "        \"\"\"Load an speaker-name prepended utterance and emotion label\"\"\"\n",
    "\n",
    "        if self.DATASET in [\"MELD\", \"IEMOCAP\"]:\n",
    "            text_path = os.path.join(\n",
    "                self.ROOT_DIR, self.DATASET, \"raw-texts\", self.SPLIT, uttid + \".json\"\n",
    "            )\n",
    "        elif self.DATASET == \"MELD_IEMOCAP\":\n",
    "            assert len(uttid.split(\"/\")) == 4\n",
    "            d_, s_, d__, u_ = uttid.split(\"/\")\n",
    "            text_path = os.path.join(self.ROOT_DIR, d_, \"raw-texts\", s_, u_ + \".json\")\n",
    "\n",
    "        with open(text_path, \"r\") as stream:\n",
    "            text = json.load(stream)\n",
    "\n",
    "        utterance = text[\"Utterance\"].strip()\n",
    "        emotion = text[\"Emotion\"]\n",
    "\n",
    "        if self.DATASET == \"MELD\":\n",
    "            speaker = text[\"Speaker\"]\n",
    "        elif self.DATASET == \"IEMOCAP\":\n",
    "            sessid = text[\"SessionID\"]\n",
    "            # https: // www.ssa.gov/oact/babynames/decades/century.html\n",
    "            speaker = {\n",
    "                \"Ses01\": {\"Female\": \"Mary\", \"Male\": \"James\"},\n",
    "                \"Ses02\": {\"Female\": \"Patricia\", \"Male\": \"John\"},\n",
    "                \"Ses03\": {\"Female\": \"Jennifer\", \"Male\": \"Robert\"},\n",
    "                \"Ses04\": {\"Female\": \"Linda\", \"Male\": \"Michael\"},\n",
    "                \"Ses05\": {\"Female\": \"Elizabeth\", \"Male\": \"William\"},\n",
    "            }[sessid][text[\"Speaker\"]]\n",
    "        elif self.DATASET == \"MELD_IEMOCAP\":\n",
    "            speaker = \"\"\n",
    "        else:\n",
    "            raise ValueError(f\"{self.DATASET} not supported!!!!!!\")\n",
    "\n",
    "        if speaker_mode is not None and speaker_mode.lower() == \"upper\":\n",
    "            utterance = speaker.upper() + \": \" + utterance\n",
    "        elif speaker_mode is not None and speaker_mode.lower() == \"title\":\n",
    "            utterance = speaker.title() + \": \" + utterance\n",
    "\n",
    "        return {\"Utterance\": utterance, \"Emotion\": emotion}\n",
    "\n",
    "    def _create_input(\n",
    "        self, diaids, speaker_mode, num_past_utterances, num_future_utterances\n",
    "    ):\n",
    "        \"\"\"Create an input which will be an input to RoBERTa.\"\"\"\n",
    "\n",
    "        args = {\n",
    "            \"diaids\": diaids,\n",
    "            \"speaker_mode\": speaker_mode,\n",
    "            \"num_past_utterances\": num_past_utterances,\n",
    "            \"num_future_utterances\": num_future_utterances,\n",
    "        }\n",
    "\n",
    "        logging.debug(f\"arguments given: {args}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_checkpoint, use_fast=True)\n",
    "        max_model_input_size = 128\n",
    "        num_truncated = 0\n",
    "\n",
    "        inputs = []\n",
    "        for diaid in tqdm(diaids):\n",
    "            ues = [\n",
    "                self._load_utterance_speaker_emotion(uttid, speaker_mode)\n",
    "                for uttid in self.utterance_ordered[diaid]\n",
    "            ]\n",
    "\n",
    "            num_tokens = [len(tokenizer(ue[\"Utterance\"])[\"input_ids\"]) for ue in ues]\n",
    "\n",
    "            for idx, ue in enumerate(ues):\n",
    "                if ue[\"Emotion\"] not in list(self.emotion2id.keys()):\n",
    "                    continue\n",
    "\n",
    "                label = self.emotion2id[ue[\"Emotion\"]]\n",
    "\n",
    "                indexes = [idx]\n",
    "                indexes_past = [\n",
    "                    i for i in range(idx - 1, idx - num_past_utterances - 1, -1)\n",
    "                ]\n",
    "                indexes_future = [\n",
    "                    i for i in range(idx + 1, idx + num_future_utterances + 1, 1)\n",
    "                ]\n",
    "\n",
    "                offset = 0\n",
    "                if len(indexes_past) < len(indexes_future):\n",
    "                    for _ in range(len(indexes_future) - len(indexes_past)):\n",
    "                        indexes_past.append(None)\n",
    "                elif len(indexes_past) > len(indexes_future):\n",
    "                    for _ in range(len(indexes_past) - len(indexes_future)):\n",
    "                        indexes_future.append(None)\n",
    "\n",
    "                for i, j in zip(indexes_past, indexes_future):\n",
    "                    if i is not None and i >= 0:\n",
    "                        indexes.insert(0, i)\n",
    "                        offset += 1\n",
    "                        if (\n",
    "                            sum([num_tokens[idx_] for idx_ in indexes])\n",
    "                            > max_model_input_size\n",
    "                        ):\n",
    "                            del indexes[0]\n",
    "                            offset -= 1\n",
    "                            num_truncated += 1\n",
    "                            break\n",
    "                    if j is not None and j < len(ues):\n",
    "                        indexes.append(j)\n",
    "                        if (\n",
    "                            sum([num_tokens[idx_] for idx_ in indexes])\n",
    "                            > max_model_input_size\n",
    "                        ):\n",
    "                            del indexes[-1]\n",
    "                            num_truncated += 1\n",
    "                            break\n",
    "\n",
    "                utterances = [ues[idx_][\"Utterance\"] for idx_ in indexes]\n",
    "\n",
    "                if num_past_utterances == 0 and num_future_utterances == 0:\n",
    "                    assert len(utterances) == 1\n",
    "                    final_utterance = utterances[0]\n",
    "\n",
    "                elif num_past_utterances > 0 and num_future_utterances == 0:\n",
    "                    if len(utterances) == 1:\n",
    "                        final_utterance = utterances[-1]\n",
    "                    else:\n",
    "                        final_utterance = (\n",
    "                            \" [CTXS] \" + \" \".join(utterances[:-1]) + \" [CTXE] \" + utterances[-1]\n",
    "                        )\n",
    "\n",
    "                elif num_past_utterances == 0 and num_future_utterances > 0:\n",
    "                    if len(utterances) == 1:\n",
    "                        final_utterance = utterances[0] + \" [CTX] \"\n",
    "                    else:\n",
    "                        final_utterance = (\n",
    "                            utterances[0] + \" [CTX] \" + \" \".join(utterances[1:])\n",
    "                        )\n",
    "\n",
    "                elif num_past_utterances > 0 and num_future_utterances > 0:\n",
    "                    if len(utterances) == 1:\n",
    "                        final_utterance = utterances[0]\n",
    "                    else:\n",
    "                        final_utterance = (\n",
    "                            \" \".join(utterances[:offset])\n",
    "                            + \" [BFR] \"\n",
    "                            + utterances[offset]\n",
    "                            + \" [AFT] \"\n",
    "                            + \" \".join(utterances[offset + 1 :])\n",
    "                        )\n",
    "                else:\n",
    "                    raise ValueError\n",
    "\n",
    "                #input_ids_attention_mask = tokenizer(final_utterance)\n",
    "                #input_ids = input_ids_attention_mask[\"input_ids\"]\n",
    "                #attention_mask = input_ids_attention_mask[\"attention_mask\"]\n",
    "\n",
    "                input_ = {\n",
    "                    \"id\": self.utterance_ordered[diaid][idx],\n",
    "                    \"utterance\": final_utterance,\n",
    "                    \"label\": self.id2emotion[label],\n",
    "                    \"num_tokens\": num_tokens[idx]\n",
    "                }\n",
    "\n",
    "                inputs.append(input_)\n",
    "\n",
    "        logging.info(f\"number of truncated utterances: {num_truncated}\")\n",
    "        return inputs\n",
    "\n",
    "    def _string2tokens(self):\n",
    "        \"\"\"Convert string to (BPE) tokens.\"\"\"\n",
    "        logging.info(f\"converting utterances into tokens ...\")\n",
    "\n",
    "        diaids = sorted(list(self.utterance_ordered.keys()))\n",
    "\n",
    "        set_seed(self.SEED)\n",
    "        random.shuffle(diaids)\n",
    "\n",
    "        if self.ONLY_UPTO:\n",
    "            logging.info(f\"Using only the first {self.ONLY_UPTO} dialogues ...\")\n",
    "            diaids = diaids[: self.ONLY_UPTO]\n",
    "\n",
    "        logging.info(f\"creating input utterance data ... \")\n",
    "        self.inputs_ = self._create_input(\n",
    "            diaids=diaids,\n",
    "            speaker_mode=self.speaker_mode,\n",
    "            num_past_utterances=self.num_past_utterances,\n",
    "            num_future_utterances=self.num_future_utterances,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.inputs_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5f80192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d0c9b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:23:29.144 INFO 567090319 - _string2tokens: converting utterances into tokens ...\n",
      "2023-06-09 16:23:29.145 INFO 567090319 - _string2tokens: creating input utterance data ... \n",
      "100%|██████████████████████████████████████| 1038/1038 [00:01<00:00, 682.29it/s]\n",
      "2023-06-09 16:23:32.071 INFO 567090319 - _create_input: number of truncated utterances: 14\n"
     ]
    }
   ],
   "source": [
    "ds_meld_train = ErcTextDataset(DATASET=\"MELD\", SPLIT=\"train\", speaker_mode=None, num_past_utterances=2, num_future_utterances=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4eefe376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:23:36.135 INFO 567090319 - _string2tokens: converting utterances into tokens ...\n",
      "2023-06-09 16:23:36.136 INFO 567090319 - _string2tokens: creating input utterance data ... \n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 713.14it/s]\n",
      "2023-06-09 16:23:37.482 INFO 567090319 - _create_input: number of truncated utterances: 1\n"
     ]
    }
   ],
   "source": [
    "ds_meld_val = ErcTextDataset(DATASET=\"MELD\", SPLIT=\"val\", speaker_mode=None, num_past_utterances=2, num_future_utterances=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "54084664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:23:37.500 INFO 567090319 - _string2tokens: converting utterances into tokens ...\n",
      "2023-06-09 16:23:37.501 INFO 567090319 - _string2tokens: creating input utterance data ... \n",
      "100%|████████████████████████████████████████| 280/280 [00:00<00:00, 686.26it/s]\n",
      "2023-06-09 16:23:39.221 INFO 567090319 - _create_input: number of truncated utterances: 0\n"
     ]
    }
   ],
   "source": [
    "ds_meld_test = ErcTextDataset(DATASET=\"MELD\", SPLIT=\"test\", speaker_mode=None, num_past_utterances=2, num_future_utterances=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "82e74599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:23:39.239 INFO 567090319 - _string2tokens: converting utterances into tokens ...\n",
      "2023-06-09 16:23:39.240 INFO 567090319 - _string2tokens: creating input utterance data ... \n",
      "100%|█████████████████████████████████████████| 100/100 [00:01<00:00, 88.07it/s]\n",
      "2023-06-09 16:23:41.692 INFO 567090319 - _create_input: number of truncated utterances: 585\n"
     ]
    }
   ],
   "source": [
    "ds_iemocap_train = ErcTextDataset(DATASET=\"IEMOCAP\", SPLIT=\"train\", speaker_mode=None, num_past_utterances=2, num_future_utterances=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8aedefd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:23:41.705 INFO 567090319 - _string2tokens: converting utterances into tokens ...\n",
      "2023-06-09 16:23:41.707 INFO 567090319 - _string2tokens: creating input utterance data ... \n",
      "100%|███████████████████████████████████████████| 20/20 [00:00<00:00, 82.40it/s]\n",
      "2023-06-09 16:23:43.243 INFO 567090319 - _create_input: number of truncated utterances: 167\n"
     ]
    }
   ],
   "source": [
    "ds_iemocap_val = ErcTextDataset(DATASET=\"IEMOCAP\", SPLIT=\"val\", speaker_mode=None, num_past_utterances=2, num_future_utterances=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "25d82305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 16:23:43.256 INFO 567090319 - _string2tokens: converting utterances into tokens ...\n",
      "2023-06-09 16:23:43.257 INFO 567090319 - _string2tokens: creating input utterance data ... \n",
      "100%|███████████████████████████████████████████| 31/31 [00:00<00:00, 81.58it/s]\n",
      "2023-06-09 16:23:44.989 INFO 567090319 - _create_input: number of truncated utterances: 285\n"
     ]
    }
   ],
   "source": [
    "ds_iemocap_test = ErcTextDataset(DATASET=\"IEMOCAP\", SPLIT=\"test\", speaker_mode=None, num_past_utterances=2, num_future_utterances=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8392c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_iemocap = [\"joy\", \"neutral\", \"sadness\", \"anger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bdde08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meld_train = pd.DataFrame(ds_meld_train.inputs_)\n",
    "df_meld_train = df_meld_train.assign(path=df_meld_train.id.apply(lambda x: f\"multimodal-datasets/MELD/raw-audios/train_resampled/{x}.wav\"))\n",
    "\n",
    "df_meld_val = pd.DataFrame(ds_meld_val.inputs_)\n",
    "df_meld_val = df_meld_val.assign(path=df_meld_val.id.apply(lambda x: f\"multimodal-datasets/MELD/raw-audios/val_resampled/{x}.wav\"))\n",
    "\n",
    "df_meld_test = pd.DataFrame(ds_meld_test.inputs_)\n",
    "df_meld_test = df_meld_test.assign(path=df_meld_test.id.apply(lambda x: f\"multimodal-datasets/MELD/raw-audios/test_resampled/{x}.wav\"))\n",
    "\n",
    "df_iemocap_train = pd.DataFrame(ds_iemocap_train.inputs_)\n",
    "df_iemocap_train = df_iemocap_train[df_iemocap_train[\"label\"].isin(keep_iemocap)]\n",
    "df_iemocap_train = df_iemocap_train.assign(path=df_iemocap_train.id.apply(lambda x: f\"multimodal-datasets/IEMOCAP/raw-audios/train/{x}.wav\"))\n",
    "\n",
    "df_iemocap_val = pd.DataFrame(ds_iemocap_val.inputs_)\n",
    "df_iemocap_val = df_iemocap_val[df_iemocap_val[\"label\"].isin(keep_iemocap)]\n",
    "df_iemocap_val = df_iemocap_val.assign(path=df_iemocap_val.id.apply(lambda x: f\"multimodal-datasets/IEMOCAP/raw-audios/val/{x}.wav\"))\n",
    "\n",
    "df_iemocap_test = pd.DataFrame(ds_iemocap_test.inputs_)\n",
    "df_iemocap_test = df_iemocap_test[df_iemocap_test[\"label\"].isin(keep_iemocap)]\n",
    "df_iemocap_test = df_iemocap_test.assign(path=df_iemocap_test.id.apply(lambda x: f\"multimodal-datasets/IEMOCAP/raw-audios/test/{x}.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0a345553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only one I know still love his parents. [B...</td>\n",
       "      <td>joy</td>\n",
       "      <td>15</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The only one I know still love his parents. Ye...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>13</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh it's not bad thing it's good thing. You kno...</td>\n",
       "      <td>joy</td>\n",
       "      <td>9</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know it's nice here, the air is sweet. You...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>14</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're not sorry you came? Not sorry, no.  I c...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>5</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>That would be no. Come on. It doesn't taste ba...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>15</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13726</th>\n",
       "      <td>Come on. It doesn't taste bad. Yeah, it's kind...</td>\n",
       "      <td>joy</td>\n",
       "      <td>9</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13727</th>\n",
       "      <td>Yeah, it's kinda sweet, sorta like, uh... Cant...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13728</th>\n",
       "      <td>Cantaloupe juice. Exactly. [BFR] You've tasted...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>12</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729</th>\n",
       "      <td>Exactly. You've tasted it? You've tasted it. [...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13730 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               utterance     label  \\\n",
       "0      The only one I know still love his parents. [B...       joy   \n",
       "1      The only one I know still love his parents. Ye...   neutral   \n",
       "2      Oh it's not bad thing it's good thing. You kno...       joy   \n",
       "3      You know it's nice here, the air is sweet. You...   sadness   \n",
       "4      You're not sorry you came? Not sorry, no.  I c...   sadness   \n",
       "...                                                  ...       ...   \n",
       "13725  That would be no. Come on. It doesn't taste ba...   neutral   \n",
       "13726  Come on. It doesn't taste bad. Yeah, it's kind...       joy   \n",
       "13727  Yeah, it's kinda sweet, sorta like, uh... Cant...   neutral   \n",
       "13728  Cantaloupe juice. Exactly. [BFR] You've tasted...  surprise   \n",
       "13729  Exactly. You've tasted it? You've tasted it. [...   neutral   \n",
       "\n",
       "       num_tokens                                               path  \n",
       "0              15  multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "1              13  multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "2               9  multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "3              14  multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "4               5  multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "...           ...                                                ...  \n",
       "13725          15  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "13726           9  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "13727           4  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "13728          12  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "13729           5  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "\n",
       "[13730 rows x 4 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_iemocap_train, df_iemocap_val, df_meld_train, df_meld_val]).reset_index(drop=True)\n",
    "df_val = df_train.sample(frac=0.100, random_state=42).reset_index(drop=True)\n",
    "df_train = df_train[~df_train[\"id\"].isin(df_val[\"id\"].tolist())].reset_index(drop=True).drop(columns=[\"id\"])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9fb6c50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"num_tokens\"].quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "80519898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"num_tokens\"].quantile(q=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cbf90f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'neutral', 'sadness', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"path\"].apply(lambda x: True if \"IEMOCAP\" in x else False)][\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "518f86e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses04M_script02_1_M005</td>\n",
       "      <td>The flashlight; the silver one.  There's only ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses03F_impro05_F016</td>\n",
       "      <td>Did you lock- Did you lock it even? You probab...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dia155_utt10</td>\n",
       "      <td>Oh you’re serious. Sure! Great! Well umm [BFR]...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dia626_utt9</td>\n",
       "      <td>Whoa! Are you okay? Whew! Stood up to fast, go...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dia449_utt4</td>\n",
       "      <td>I’m so-so sorry about yesterday. I-I’m really ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>dia255_utt7</td>\n",
       "      <td>I wasn't thinking. I was too busy fallin'... D...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>Ses03M_script02_1_M014</td>\n",
       "      <td>Are you cold?  Do you want my jacket? We shoul...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>dia546_utt4</td>\n",
       "      <td>Which one do you think she is? May I help you?...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>dia262_utt0</td>\n",
       "      <td>[BFR] Ok, you can do this. [AFT] It's just li...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>dia336_utt21</td>\n",
       "      <td>Okay, stop what you’re doing, I need envelope ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1539 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "0     Ses04M_script02_1_M005   \n",
       "1        Ses03F_impro05_F016   \n",
       "2               dia155_utt10   \n",
       "3                dia626_utt9   \n",
       "4                dia449_utt4   \n",
       "...                      ...   \n",
       "1534             dia255_utt7   \n",
       "1535  Ses03M_script02_1_M014   \n",
       "1536             dia546_utt4   \n",
       "1537             dia262_utt0   \n",
       "1538            dia336_utt21   \n",
       "\n",
       "                                              utterance    label  \\\n",
       "0     The flashlight; the silver one.  There's only ...  neutral   \n",
       "1     Did you lock- Did you lock it even? You probab...    anger   \n",
       "2     Oh you’re serious. Sure! Great! Well umm [BFR]...  neutral   \n",
       "3     Whoa! Are you okay? Whew! Stood up to fast, go...  neutral   \n",
       "4     I’m so-so sorry about yesterday. I-I’m really ...      joy   \n",
       "...                                                 ...      ...   \n",
       "1534  I wasn't thinking. I was too busy fallin'... D...      joy   \n",
       "1535  Are you cold?  Do you want my jacket? We shoul...      joy   \n",
       "1536  Which one do you think she is? May I help you?...  neutral   \n",
       "1537   [BFR] Ok, you can do this. [AFT] It's just li...  neutral   \n",
       "1538  Okay, stop what you’re doing, I need envelope ...      joy   \n",
       "\n",
       "                                                   path  \n",
       "0     multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "1     multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "2     multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "3     multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "4     multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "...                                                 ...  \n",
       "1534  multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "1535  multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "1536  multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "1537  multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "1538  multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "\n",
       "[1539 rows x 4 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b97071c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BFR] Brian, I need help. [AFT] Babe, I don't...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian, I need help. [BFR] Babe, I don't know w...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babe, I don't know what to tell you.  Don't gi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wish I had some answers for you, babe.  I me...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I went to school and I got my degree.  And I g...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>Oh, it is. It isn't. [BFR] It is. [AFT] Isn't!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>It isn't. It is. [BFR] Isn't! [AFT]</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>[BFR] Yeah baby! [AFT] I’m really glad you gu...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>Yeah baby! [BFR] I’m really glad you guys are ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>Hey.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3851 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              utterance    label  \\\n",
       "0      [BFR] Brian, I need help. [AFT] Babe, I don't...  sadness   \n",
       "1     Brian, I need help. [BFR] Babe, I don't know w...  neutral   \n",
       "2     Babe, I don't know what to tell you.  Don't gi...  neutral   \n",
       "3     I wish I had some answers for you, babe.  I me...  neutral   \n",
       "4     I went to school and I got my degree.  And I g...  neutral   \n",
       "...                                                 ...      ...   \n",
       "3846     Oh, it is. It isn't. [BFR] It is. [AFT] Isn't!  neutral   \n",
       "3847               It isn't. It is. [BFR] Isn't! [AFT]     anger   \n",
       "3848   [BFR] Yeah baby! [AFT] I’m really glad you gu...      joy   \n",
       "3849  Yeah baby! [BFR] I’m really glad you guys are ...  neutral   \n",
       "3850                                               Hey.  neutral   \n",
       "\n",
       "                                                   path  \n",
       "0     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "1     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "2     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "3     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "4     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "...                                                 ...  \n",
       "3846  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "3847  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "3848  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "3849  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "3850  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "\n",
       "[3851 rows x 3 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([df_iemocap_test.drop(columns=[\"id\"]), df_meld_test.drop(columns=[\"id\"])]).reset_index(drop=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ed92bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a3c98330",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_file = []\n",
    "for i, row in df_train.iterrows():\n",
    "    if not os.path.isfile(f\"../{row['path']}\"):\n",
    "        not_file.append(row['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b2158a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_file_test = []\n",
    "for i, row in df_test.iterrows():\n",
    "    if not os.path.isfile(f\"../{row['path']}\"):\n",
    "        not_file_test.append(row['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3de5a9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multimodal-datasets/MELD/raw-audios/train_resampled/dia125_utt3.wav',\n",
       " 'multimodal-datasets/MELD/raw-audios/val_resampled/dia110_utt7.wav']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ad7a0711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_file_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a47aba12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13730"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ffc091f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train[\"path\"] != 'multimodal-datasets/MELD/raw-audios/train_resampled/dia125_utt3.wav']\n",
    "df_train = df_train[df_train[\"path\"] != 'multimodal-datasets/MELD/raw-audios/val_resampled/dia110_utt7.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7c540834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13728"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c8ddf765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3851"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "84d5bcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only one I know still love his parents. [B...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The only one I know still love his parents. Ye...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh it's not bad thing it's good thing. You kno...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know it's nice here, the air is sweet. You...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're not sorry you came? Not sorry, no.  I c...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/train/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>That would be no. Come on. It doesn't taste ba...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13726</th>\n",
       "      <td>Come on. It doesn't taste bad. Yeah, it's kind...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13727</th>\n",
       "      <td>Yeah, it's kinda sweet, sorta like, uh... Cant...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13728</th>\n",
       "      <td>Cantaloupe juice. Exactly. [BFR] You've tasted...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729</th>\n",
       "      <td>Exactly. You've tasted it? You've tasted it. [...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13728 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               utterance     label  \\\n",
       "0      The only one I know still love his parents. [B...       joy   \n",
       "1      The only one I know still love his parents. Ye...   neutral   \n",
       "2      Oh it's not bad thing it's good thing. You kno...       joy   \n",
       "3      You know it's nice here, the air is sweet. You...   sadness   \n",
       "4      You're not sorry you came? Not sorry, no.  I c...   sadness   \n",
       "...                                                  ...       ...   \n",
       "13725  That would be no. Come on. It doesn't taste ba...   neutral   \n",
       "13726  Come on. It doesn't taste bad. Yeah, it's kind...       joy   \n",
       "13727  Yeah, it's kinda sweet, sorta like, uh... Cant...   neutral   \n",
       "13728  Cantaloupe juice. Exactly. [BFR] You've tasted...  surprise   \n",
       "13729  Exactly. You've tasted it? You've tasted it. [...   neutral   \n",
       "\n",
       "                                                    path  \n",
       "0      multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "1      multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "2      multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "3      multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "4      multimodal-datasets/IEMOCAP/raw-audios/train/S...  \n",
       "...                                                  ...  \n",
       "13725  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "13726  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "13727  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "13728  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "13729  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "\n",
       "[13728 rows x 3 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4af9bc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BFR] Brian, I need help. [AFT] Babe, I don't...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian, I need help. [BFR] Babe, I don't know w...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babe, I don't know what to tell you.  Don't gi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wish I had some answers for you, babe.  I me...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I went to school and I got my degree.  And I g...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>Oh, it is. It isn't. [BFR] It is. [AFT] Isn't!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>It isn't. It is. [BFR] Isn't! [AFT]</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>[BFR] Yeah baby! [AFT] I’m really glad you gu...</td>\n",
       "      <td>joy</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>Yeah baby! [BFR] I’m really glad you guys are ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>Hey.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/test_resam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3851 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              utterance    label  \\\n",
       "0      [BFR] Brian, I need help. [AFT] Babe, I don't...  sadness   \n",
       "1     Brian, I need help. [BFR] Babe, I don't know w...  neutral   \n",
       "2     Babe, I don't know what to tell you.  Don't gi...  neutral   \n",
       "3     I wish I had some answers for you, babe.  I me...  neutral   \n",
       "4     I went to school and I got my degree.  And I g...  neutral   \n",
       "...                                                 ...      ...   \n",
       "3846     Oh, it is. It isn't. [BFR] It is. [AFT] Isn't!  neutral   \n",
       "3847               It isn't. It is. [BFR] Isn't! [AFT]     anger   \n",
       "3848   [BFR] Yeah baby! [AFT] I’m really glad you gu...      joy   \n",
       "3849  Yeah baby! [BFR] I’m really glad you guys are ...  neutral   \n",
       "3850                                               Hey.  neutral   \n",
       "\n",
       "                                                   path  \n",
       "0     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "1     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "2     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "3     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "4     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "...                                                 ...  \n",
       "3846  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "3847  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "3848  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "3849  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "3850  multimodal-datasets/MELD/raw-audios/test_resam...  \n",
       "\n",
       "[3851 rows x 3 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bfec7417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(drop=True).to_csv(\"train_text_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a4236212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.reset_index(drop=True).to_csv(\"test_text_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050bcb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
