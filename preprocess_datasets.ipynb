{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4391d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"utility and helper functions / classes.\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "\n",
    "def make_MELD_IEMOCAP():\n",
    "\n",
    "    SEED = 42\n",
    "    ratios = {\"train\": 0.9, \"val\": 0.1, \"test\": 0}\n",
    "\n",
    "    assert sum(list(ratios.values())) == 1\n",
    "\n",
    "    utterance_ordered = {}\n",
    "\n",
    "    with open(f\"./MELD/utterance-ordered.json\", \"r\") as stream:\n",
    "        utterance_ordered[\"MELD\"] = json.load(stream)\n",
    "\n",
    "    with open(f\"./IEMOCAP/utterance-ordered.json\", \"r\") as stream:\n",
    "        utterance_ordered[\"IEMOCAP\"] = json.load(stream)\n",
    "\n",
    "    diaids_merged = []\n",
    "\n",
    "    for DATASET in [\"MELD\", \"IEMOCAP\"]:\n",
    "        for SPLIT in [\"train\", \"val\", \"test\"]:\n",
    "            diaids = list(utterance_ordered[DATASET][SPLIT].keys())\n",
    "            for diaid in diaids:\n",
    "                diaids_merged.append(f\"{DATASET}/{SPLIT}/{diaid}\")\n",
    "\n",
    "    random.seed(SEED)\n",
    "    random.shuffle(diaids_merged)\n",
    "\n",
    "    train_idx = int(len(diaids_merged) * ratios[\"train\"])\n",
    "    val_idx = int(len(diaids_merged) * (ratios[\"train\"] + ratios[\"val\"]))\n",
    "\n",
    "    diaids_train = diaids_merged[:train_idx]\n",
    "    diaids_val = diaids_merged[train_idx:val_idx]\n",
    "    diaids_test = diaids_merged[val_idx:]\n",
    "\n",
    "    assert len(diaids_merged) == (\n",
    "        len(diaids_train) + len(diaids_val) + len(diaids_test)\n",
    "    )\n",
    "\n",
    "    diaids_merged = {\"train\": diaids_train, \"val\": diaids_val, \"test\": diaids_test}\n",
    "\n",
    "    utterance_ordered_merged = {}\n",
    "\n",
    "    for SPLIT in [\"train\", \"val\", \"test\"]:\n",
    "        utterance_ordered_merged[SPLIT] = {}\n",
    "\n",
    "        for diaid in tqdm(diaids_merged[SPLIT]):\n",
    "\n",
    "            d_, s_, d__ = diaid.split(\"/\")\n",
    "            utterance_ordered_merged[SPLIT][diaid] = [\n",
    "                f\"{d_}/{s_}/{d__}/{uttid}\" for uttid in utterance_ordered[d_][s_][d__]\n",
    "            ]\n",
    "\n",
    "    assert len(\n",
    "        [\n",
    "            val___\n",
    "            for key, val in utterance_ordered.items()\n",
    "            for key_, val_ in val.items()\n",
    "            for key__, val__ in val_.items()\n",
    "            for val___ in val__\n",
    "        ]\n",
    "    ) == len(\n",
    "        [\n",
    "            val__\n",
    "            for key, val in utterance_ordered_merged.items()\n",
    "            for key_, val_ in val.items()\n",
    "            for val__ in val_\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(\"./utterance-ordered-MELD_IEMOCAP.json\", \"w\") as stream:\n",
    "        json.dump(utterance_ordered_merged, stream, indent=4)\n",
    "\n",
    "\n",
    "def get_num_classes(DATASET: str) -> int:\n",
    "    \"\"\"Get the number of classes to be classified by dataset.\"\"\"\n",
    "    if DATASET == \"MELD\":\n",
    "        NUM_CLASSES = 7\n",
    "    elif DATASET == \"IEMOCAP\":\n",
    "        NUM_CLASSES = 6\n",
    "    elif DATASET == \"MELD_IEMOCAP\":\n",
    "        NUM_CLASSES = 7\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return 7\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions) -> dict:\n",
    "    \"\"\"Return f1_weighted, f1_micro, and f1_macro scores.\"\"\"\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "    f1_weighted = f1_score(label_ids, preds, average=\"weighted\")\n",
    "    f1_micro = f1_score(label_ids, preds, average=\"micro\")\n",
    "    f1_macro = f1_score(label_ids, preds, average=\"macro\")\n",
    "\n",
    "    return {\"f1_weighted\": f1_weighted, \"f1_micro\": f1_micro, \"f1_macro\": f1_macro}\n",
    "\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"Set random seed to a fixed value.\n",
    "\n",
    "    Set everything to be deterministic\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def get_emotion2id(DATASET: str) -> Tuple[dict, dict]:\n",
    "    \"\"\"Get a dict that converts string class to numbers.\"\"\"\n",
    "    emotions = [\n",
    "        \"neutral\",\n",
    "        \"joy\",\n",
    "        \"surprise\",\n",
    "        \"anger\",\n",
    "        \"sadness\",\n",
    "        \"disgust\",\n",
    "        \"fear\",\n",
    "    ]\n",
    "        \n",
    "    emotion2id = {\n",
    "        \"neutral\": 0,\n",
    "        \"joy\": 1,\n",
    "        \"happiness\": 1,\n",
    "        \"excited\": 1,\n",
    "        \"surprise\": 2,\n",
    "        \"anger\": 3,\n",
    "        \"frustration\": 3,\n",
    "        \"sadness\": 4,\n",
    "        \"disgust\": 5,\n",
    "        \"fear\": 6,\n",
    "    }\n",
    "    id2emotion = {idx: emotion for idx, emotion in enumerate(emotions)}\n",
    "\n",
    "    return emotion2id, id2emotion\n",
    "\n",
    "\n",
    "class ErcTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        DATASET=\"MELD\",\n",
    "        SPLIT=\"train\",\n",
    "        speaker_mode=\"upper\",\n",
    "        num_past_utterances=0,\n",
    "        num_future_utterances=0,\n",
    "        model_checkpoint=\"roberta-base\",\n",
    "        ROOT_DIR=\"./\",\n",
    "        ONLY_UPTO=False,\n",
    "        SEED=0,\n",
    "    ):\n",
    "        \"\"\"Initialize emotion recognition in conversation text modality dataset class.\"\"\"\n",
    "\n",
    "        self.DATASET = DATASET\n",
    "        self.ROOT_DIR = ROOT_DIR\n",
    "        self.SPLIT = SPLIT\n",
    "        self.speaker_mode = speaker_mode\n",
    "        self.num_past_utterances = num_past_utterances\n",
    "        self.num_future_utterances = num_future_utterances\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.emotion2id, self.id2emotion = get_emotion2id(self.DATASET)\n",
    "        self.ONLY_UPTO = ONLY_UPTO\n",
    "        self.SEED = SEED\n",
    "\n",
    "        self._load_emotions()\n",
    "        self._load_utterance_ordered()\n",
    "        self._string2tokens()\n",
    "\n",
    "    def _load_emotions(self):\n",
    "        \"\"\"Load the supervised labels\"\"\"\n",
    "        if self.DATASET in [\"MELD\", \"IEMOCAP\"]:\n",
    "            with open(\n",
    "                os.path.join(self.ROOT_DIR, self.DATASET, \"emotions.json\"), \"r\"\n",
    "            ) as stream:\n",
    "                self.emotions = json.load(stream)[self.SPLIT]\n",
    "\n",
    "    def _load_utterance_ordered(self):\n",
    "        \"\"\"Load the ids of the utterances in order.\"\"\"\n",
    "        if self.DATASET in [\"MELD\", \"IEMOCAP\"]:\n",
    "            path = os.path.join(self.ROOT_DIR, self.DATASET, \"utterance-ordered.json\")\n",
    "        elif self.DATASET == \"MELD_IEMOCAP\":\n",
    "            path = \"./utterance-ordered-MELD_IEMOCAP.json\"\n",
    "\n",
    "        with open(path, \"r\") as stream:\n",
    "            self.utterance_ordered = json.load(stream)[self.SPLIT]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_)\n",
    "\n",
    "    def _load_utterance_speaker_emotion(self, uttid, speaker_mode) -> dict:\n",
    "        \"\"\"Load an speaker-name prepended utterance and emotion label\"\"\"\n",
    "\n",
    "        if self.DATASET in [\"MELD\", \"IEMOCAP\"]:\n",
    "            text_path = os.path.join(\n",
    "                self.ROOT_DIR, self.DATASET, \"raw-texts\", self.SPLIT, uttid + \".json\"\n",
    "            )\n",
    "        elif self.DATASET == \"MELD_IEMOCAP\":\n",
    "            assert len(uttid.split(\"/\")) == 4\n",
    "            d_, s_, d__, u_ = uttid.split(\"/\")\n",
    "            text_path = os.path.join(self.ROOT_DIR, d_, \"raw-texts\", s_, u_ + \".json\")\n",
    "\n",
    "        with open(text_path, \"r\") as stream:\n",
    "            text = json.load(stream)\n",
    "\n",
    "        utterance = text[\"Utterance\"].strip()\n",
    "        emotion = text[\"Emotion\"]\n",
    "\n",
    "        if self.DATASET == \"MELD\":\n",
    "            speaker = text[\"Speaker\"]\n",
    "        elif self.DATASET == \"IEMOCAP\":\n",
    "            sessid = text[\"SessionID\"]\n",
    "            # https: // www.ssa.gov/oact/babynames/decades/century.html\n",
    "            speaker = {\n",
    "                \"Ses01\": {\"Female\": \"Mary\", \"Male\": \"James\"},\n",
    "                \"Ses02\": {\"Female\": \"Patricia\", \"Male\": \"John\"},\n",
    "                \"Ses03\": {\"Female\": \"Jennifer\", \"Male\": \"Robert\"},\n",
    "                \"Ses04\": {\"Female\": \"Linda\", \"Male\": \"Michael\"},\n",
    "                \"Ses05\": {\"Female\": \"Elizabeth\", \"Male\": \"William\"},\n",
    "            }[sessid][text[\"Speaker\"]]\n",
    "        elif self.DATASET == \"MELD_IEMOCAP\":\n",
    "            speaker = \"\"\n",
    "        else:\n",
    "            raise ValueError(f\"{self.DATASET} not supported!!!!!!\")\n",
    "\n",
    "        if speaker_mode is not None and speaker_mode.lower() == \"upper\":\n",
    "            utterance = speaker.upper() + \": \" + utterance\n",
    "        elif speaker_mode is not None and speaker_mode.lower() == \"title\":\n",
    "            utterance = speaker.title() + \": \" + utterance\n",
    "\n",
    "        return {\"Utterance\": utterance, \"Emotion\": emotion}\n",
    "\n",
    "    def _create_input(\n",
    "        self, diaids, speaker_mode, num_past_utterances, num_future_utterances\n",
    "    ):\n",
    "        \"\"\"Create an input which will be an input to RoBERTa.\"\"\"\n",
    "\n",
    "        args = {\n",
    "            \"diaids\": diaids,\n",
    "            \"speaker_mode\": speaker_mode,\n",
    "            \"num_past_utterances\": num_past_utterances,\n",
    "            \"num_future_utterances\": num_future_utterances,\n",
    "        }\n",
    "\n",
    "        logging.debug(f\"arguments given: {args}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_checkpoint, use_fast=True)\n",
    "        max_model_input_size = 128\n",
    "        num_truncated = 0\n",
    "\n",
    "        inputs = []\n",
    "        for diaid in tqdm(diaids):\n",
    "            ues = [\n",
    "                self._load_utterance_speaker_emotion(uttid, speaker_mode)\n",
    "                for uttid in self.utterance_ordered[diaid]\n",
    "            ]\n",
    "\n",
    "            num_tokens = [len(tokenizer(ue[\"Utterance\"])[\"input_ids\"]) for ue in ues]\n",
    "\n",
    "            for idx, ue in enumerate(ues):\n",
    "                if ue[\"Emotion\"] not in list(self.emotion2id.keys()):\n",
    "                    continue\n",
    "\n",
    "                label = self.emotion2id[ue[\"Emotion\"]]\n",
    "\n",
    "                indexes = [idx]\n",
    "                indexes_past = [\n",
    "                    i for i in range(idx - 1, idx - num_past_utterances - 1, -1)\n",
    "                ]\n",
    "                indexes_future = [\n",
    "                    i for i in range(idx + 1, idx + num_future_utterances + 1, 1)\n",
    "                ]\n",
    "\n",
    "                offset = 0\n",
    "                if len(indexes_past) < len(indexes_future):\n",
    "                    for _ in range(len(indexes_future) - len(indexes_past)):\n",
    "                        indexes_past.append(None)\n",
    "                elif len(indexes_past) > len(indexes_future):\n",
    "                    for _ in range(len(indexes_past) - len(indexes_future)):\n",
    "                        indexes_future.append(None)\n",
    "\n",
    "                for i, j in zip(indexes_past, indexes_future):\n",
    "                    if i is not None and i >= 0:\n",
    "                        indexes.insert(0, i)\n",
    "                        offset += 1\n",
    "                        if (\n",
    "                            sum([num_tokens[idx_] for idx_ in indexes])\n",
    "                            > max_model_input_size\n",
    "                        ):\n",
    "                            del indexes[0]\n",
    "                            offset -= 1\n",
    "                            num_truncated += 1\n",
    "                            break\n",
    "                    if j is not None and j < len(ues):\n",
    "                        indexes.append(j)\n",
    "                        if (\n",
    "                            sum([num_tokens[idx_] for idx_ in indexes])\n",
    "                            > max_model_input_size\n",
    "                        ):\n",
    "                            del indexes[-1]\n",
    "                            num_truncated += 1\n",
    "                            break\n",
    "\n",
    "                utterances = [ues[idx_][\"Utterance\"] for idx_ in indexes]\n",
    "\n",
    "                if num_past_utterances == 0 and num_future_utterances == 0:\n",
    "                    assert len(utterances) == 1\n",
    "                    final_utterance = utterances[0]\n",
    "\n",
    "                elif num_past_utterances > 0 and num_future_utterances == 0:\n",
    "                    if len(utterances) == 1:\n",
    "                        final_utterance = \" [SEP] \" + utterances[-1]\n",
    "                    else:\n",
    "                        final_utterance = (\n",
    "                            \" \".join(utterances[:-1]) + \" [SEP] \" + utterances[-1]\n",
    "                        )\n",
    "\n",
    "                elif num_past_utterances == 0 and num_future_utterances > 0:\n",
    "                    if len(utterances) == 1:\n",
    "                        final_utterance = utterances[0] + \" [SEP] \"\n",
    "                    else:\n",
    "                        final_utterance = (\n",
    "                            utterances[0] + \" [SEP] \" + \" \".join(utterances[1:])\n",
    "                        )\n",
    "\n",
    "                elif num_past_utterances > 0 and num_future_utterances > 0:\n",
    "                    if len(utterances) == 1:\n",
    "                        final_utterance = \" [SEP] \" + utterances[0] + \" [SEP] \"\n",
    "                    else:\n",
    "                        final_utterance = (\n",
    "                            \" \".join(utterances[:offset])\n",
    "                            + \" [SEP] \"\n",
    "                            + utterances[offset]\n",
    "                            + \" [SEP] \"\n",
    "                            + \" \".join(utterances[offset + 1 :])\n",
    "                        )\n",
    "                else:\n",
    "                    raise ValueError\n",
    "\n",
    "                #input_ids_attention_mask = tokenizer(final_utterance)\n",
    "                #input_ids = input_ids_attention_mask[\"input_ids\"]\n",
    "                #attention_mask = input_ids_attention_mask[\"attention_mask\"]\n",
    "\n",
    "                input_ = {\n",
    "                    \"id\": self.utterance_ordered[diaid][idx],\n",
    "                    \"utterance\": final_utterance,\n",
    "                    \"label\": self.id2emotion[label],\n",
    "                }\n",
    "\n",
    "                inputs.append(input_)\n",
    "\n",
    "        logging.info(f\"number of truncated utterances: {num_truncated}\")\n",
    "        return inputs\n",
    "\n",
    "    def _string2tokens(self):\n",
    "        \"\"\"Convert string to (BPE) tokens.\"\"\"\n",
    "        logging.info(f\"converting utterances into tokens ...\")\n",
    "\n",
    "        diaids = sorted(list(self.utterance_ordered.keys()))\n",
    "\n",
    "        set_seed(self.SEED)\n",
    "        random.shuffle(diaids)\n",
    "\n",
    "        if self.ONLY_UPTO:\n",
    "            logging.info(f\"Using only the first {self.ONLY_UPTO} dialogues ...\")\n",
    "            diaids = diaids[: self.ONLY_UPTO]\n",
    "\n",
    "        logging.info(f\"creating input utterance data ... \")\n",
    "        self.inputs_ = self._create_input(\n",
    "            diaids=diaids,\n",
    "            speaker_mode=self.speaker_mode,\n",
    "            num_past_utterances=self.num_past_utterances,\n",
    "            num_future_utterances=self.num_future_utterances,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.inputs_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0ae85ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass ErcTextDataset(torch.utils.data.Dataset):\\n    def __init__(\\n        self,\\n        DATASET=\"MELD\",\\n        SPLIT=\"train\",\\n        speaker_mode=\"upper\",\\n        num_past_utterances=0,\\n        num_future_utterances=0,\\n        model_checkpoint=\"roberta-base\",\\n        ROOT_DIR=\"./\",\\n        ONLY_UPTO=False,\\n        SEED=0,\\n    ):\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class ErcTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        DATASET=\"MELD\",\n",
    "        SPLIT=\"train\",\n",
    "        speaker_mode=\"upper\",\n",
    "        num_past_utterances=0,\n",
    "        num_future_utterances=0,\n",
    "        model_checkpoint=\"roberta-base\",\n",
    "        ROOT_DIR=\"./\",\n",
    "        ONLY_UPTO=False,\n",
    "        SEED=0,\n",
    "    ):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5432c98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 13:24:27.092 INFO 2447889311 - _string2tokens: converting utterances into tokens ...\n",
      "2023-05-11 13:24:27.093 INFO 2447889311 - _string2tokens: creating input utterance data ... \n",
      "100%|█████████████████████████████████████| 1038/1038 [00:00<00:00, 1417.67it/s]\n",
      "2023-05-11 13:24:29.891 INFO 2447889311 - _create_input: number of truncated utterances: 1\n"
     ]
    }
   ],
   "source": [
    "ds_meld_train = ErcTextDataset(DATASET=\"MELD\", SPLIT=\"train\", speaker_mode=None, num_past_utterances=1, num_future_utterances=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60920a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 13:24:29.905 INFO 2447889311 - _string2tokens: converting utterances into tokens ...\n",
      "2023-05-11 13:24:29.906 INFO 2447889311 - _string2tokens: creating input utterance data ... \n",
      "100%|███████████████████████████████████████| 114/114 [00:00<00:00, 1382.50it/s]\n",
      "2023-05-11 13:24:31.312 INFO 2447889311 - _create_input: number of truncated utterances: 0\n"
     ]
    }
   ],
   "source": [
    "ds_meld_val = ErcTextDataset(DATASET=\"MELD\", SPLIT=\"val\", speaker_mode=None, num_past_utterances=1, num_future_utterances=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "109b8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 13:24:31.326 INFO 2447889311 - _string2tokens: converting utterances into tokens ...\n",
      "2023-05-11 13:24:31.327 INFO 2447889311 - _string2tokens: creating input utterance data ... \n",
      "100%|███████████████████████████████████████| 280/280 [00:00<00:00, 1399.51it/s]\n",
      "2023-05-11 13:24:32.827 INFO 2447889311 - _create_input: number of truncated utterances: 0\n"
     ]
    }
   ],
   "source": [
    "ds_meld_test = ErcTextDataset(DATASET=\"MELD\", SPLIT=\"test\", speaker_mode=None, num_past_utterances=1, num_future_utterances=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09a3f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 13:24:32.839 INFO 2447889311 - _string2tokens: converting utterances into tokens ...\n",
      "2023-05-11 13:24:32.840 INFO 2447889311 - _string2tokens: creating input utterance data ... \n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 200.39it/s]\n",
      "2023-05-11 13:24:34.686 INFO 2447889311 - _create_input: number of truncated utterances: 56\n"
     ]
    }
   ],
   "source": [
    "ds_iemocap_train = ErcTextDataset(DATASET=\"IEMOCAP\", SPLIT=\"train\", speaker_mode=None, num_past_utterances=1, num_future_utterances=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ebf906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 13:24:34.699 INFO 2447889311 - _string2tokens: converting utterances into tokens ...\n",
      "2023-05-11 13:24:34.700 INFO 2447889311 - _string2tokens: creating input utterance data ... \n",
      "100%|██████████████████████████████████████████| 20/20 [00:00<00:00, 180.59it/s]\n",
      "2023-05-11 13:24:36.126 INFO 2447889311 - _create_input: number of truncated utterances: 19\n"
     ]
    }
   ],
   "source": [
    "ds_iemocap_val = ErcTextDataset(DATASET=\"IEMOCAP\", SPLIT=\"val\", speaker_mode=None, num_past_utterances=1, num_future_utterances=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a1188fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 13:24:36.137 INFO 2447889311 - _string2tokens: converting utterances into tokens ...\n",
      "2023-05-11 13:24:36.138 INFO 2447889311 - _string2tokens: creating input utterance data ... \n",
      "100%|██████████████████████████████████████████| 31/31 [00:00<00:00, 176.07it/s]\n",
      "2023-05-11 13:24:37.890 INFO 2447889311 - _create_input: number of truncated utterances: 33\n"
     ]
    }
   ],
   "source": [
    "ds_iemocap_test = ErcTextDataset(DATASET=\"IEMOCAP\", SPLIT=\"test\", speaker_mode=None, num_past_utterances=1, num_future_utterances=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2bf5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e49d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meld_train = pd.DataFrame(ds_meld_train.inputs_)\n",
    "df_meld_train = df_meld_train.assign(path=df_meld_train.id.apply(lambda x: f\"multimodal-datasets/MELD/raw-audios/train_resampled/{x}.wav\"))\n",
    "\n",
    "df_meld_val = pd.DataFrame(ds_meld_val.inputs_)\n",
    "df_meld_val = df_meld_val.assign(path=df_meld_val.id.apply(lambda x: f\"multimodal-datasets/MELD/raw-audios/val_resampled/{x}.wav\"))\n",
    "\n",
    "df_meld_test = pd.DataFrame(ds_meld_test.inputs_)\n",
    "df_meld_test = df_meld_test.assign(path=df_meld_test.id.apply(lambda x: f\"multimodal-datasets/MELD/raw-audios/test_resampled/{x}.wav\"))\n",
    "\n",
    "df_iemocap_train = pd.DataFrame(ds_iemocap_train.inputs_)\n",
    "df_iemocap_train = df_iemocap_train.assign(path=df_iemocap_train.id.apply(lambda x: f\"multimodal-datasets/IEMOCAP/raw-audios/train/{x}.wav\"))\n",
    "\n",
    "df_iemocap_val = pd.DataFrame(ds_iemocap_val.inputs_)\n",
    "df_iemocap_val = df_iemocap_val.assign(path=df_iemocap_val.id.apply(lambda x: f\"multimodal-datasets/IEMOCAP/raw-audios/val/{x}.wav\"))\n",
    "\n",
    "df_iemocap_test = pd.DataFrame(ds_iemocap_test.inputs_)\n",
    "df_iemocap_test = df_iemocap_test.assign(path=df_iemocap_test.id.apply(lambda x: f\"multimodal-datasets/IEMOCAP/raw-audios/test/{x}.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "489da56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SEP] OK, we got the cole slaw, we got the bu...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK, we got the cole slaw, we got the buns... [...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We've got the ground-up flesh of formerly cute...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SEP] Wait a minute, hold it.  Johnson! Will ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wait a minute, hold it.  Johnson! Will you com...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>God, that's like a whole problem with like-- B...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>if you ever come out to Montgomery, I mean, yo...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>I'll [SEP] call up the Sprint call center and,...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>Wow, alright. Well, thanks. And, uh, you- you ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>Alright. Take Care. [SEP] You too. [SEP]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15868 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               utterance    label  \\\n",
       "0       [SEP] OK, we got the cole slaw, we got the bu...  neutral   \n",
       "1      OK, we got the cole slaw, we got the buns... [...  disgust   \n",
       "2      We've got the ground-up flesh of formerly cute...  neutral   \n",
       "3       [SEP] Wait a minute, hold it.  Johnson! Will ...  neutral   \n",
       "4      Wait a minute, hold it.  Johnson! Will you com...  neutral   \n",
       "...                                                  ...      ...   \n",
       "15863  God, that's like a whole problem with like-- B...  neutral   \n",
       "15864  if you ever come out to Montgomery, I mean, yo...  neutral   \n",
       "15865  I'll [SEP] call up the Sprint call center and,...  neutral   \n",
       "15866  Wow, alright. Well, thanks. And, uh, you- you ...  neutral   \n",
       "15867          Alright. Take Care. [SEP] You too. [SEP]   neutral   \n",
       "\n",
       "                                                    path  \n",
       "0      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "1      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "2      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "3      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "4      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "...                                                  ...  \n",
       "15863  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "15864  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "15865  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "15866  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "15867  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "\n",
       "[15868 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([df_meld_train.drop(columns=[\"id\"]), df_iemocap_train.drop(columns=[\"id\"]), df_iemocap_val.drop(columns=[\"id\"])]).reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4210276b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SEP] Brian, I need help. [SEP] Babe, I don't...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian, I need help. [SEP] Babe, I don't know w...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't--I'm just--I'm thinking maybe I should...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well, of course not, but what are you going to...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't know.  I mean, what am I supposed to d...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>Exactly. [SEP] You've tasted it? You've tasted...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>You've tasted it? You've tasted it. [SEP] Uh h...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>Uh huh. [SEP] Oh, you've tasted it. [SEP] You ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>Oh, you've tasted it. [SEP] You can keep sayin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>You can keep saying it, but it won't stop bein...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2759 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              utterance     label  \\\n",
       "0      [SEP] Brian, I need help. [SEP] Babe, I don't...   sadness   \n",
       "1     Brian, I need help. [SEP] Babe, I don't know w...   neutral   \n",
       "2     I don't--I'm just--I'm thinking maybe I should...   neutral   \n",
       "3     Well, of course not, but what are you going to...     anger   \n",
       "4     I don't know.  I mean, what am I supposed to d...     anger   \n",
       "...                                                 ...       ...   \n",
       "2754  Exactly. [SEP] You've tasted it? You've tasted...  surprise   \n",
       "2755  You've tasted it? You've tasted it. [SEP] Uh h...   neutral   \n",
       "2756  Uh huh. [SEP] Oh, you've tasted it. [SEP] You ...     anger   \n",
       "2757  Oh, you've tasted it. [SEP] You can keep sayin...   neutral   \n",
       "2758  You can keep saying it, but it won't stop bein...     anger   \n",
       "\n",
       "                                                   path  \n",
       "0     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "1     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "2     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "3     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "4     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "...                                                 ...  \n",
       "2754  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "2755  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "2756  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "2757  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "2758  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "\n",
       "[2759 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([df_iemocap_test.drop(columns=[\"id\"]), df_meld_val.drop(columns=[\"id\"])]).reset_index(drop=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3faf8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0470b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_file = []\n",
    "for i, row in train_df.iterrows():\n",
    "    if not os.path.isfile(f\"../{row['path']}\"):\n",
    "        not_file.append(row['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc71d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not_file = []\n",
    "for i, row in test_df.iterrows():\n",
    "    if not os.path.isfile(f\"../{row['path']}\"):\n",
    "        not_file.append(row['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3864c589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multimodal-datasets/MELD/raw-audios/train_resampled/dia125_utt3.wav',\n",
       " 'multimodal-datasets/MELD/raw-audios/val_resampled/dia110_utt7.wav']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd80850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15868"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cf1195d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[\"path\"] != 'multimodal-datasets/MELD/raw-audios/train_resampled/dia125_utt3.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ca30f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15867"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1953eabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2759"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2361e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df[\"path\"] != 'multimodal-datasets/MELD/raw-audios/val_resampled/dia110_utt7.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6327dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2758"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ee23d843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SEP] OK, we got the cole slaw, we got the bu...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK, we got the cole slaw, we got the buns... [...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We've got the ground-up flesh of formerly cute...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SEP] Wait a minute, hold it.  Johnson! Will ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wait a minute, hold it.  Johnson! Will you com...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/train_resa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>God, that's like a whole problem with like-- B...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>if you ever come out to Montgomery, I mean, yo...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>I'll [SEP] call up the Sprint call center and,...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>Wow, alright. Well, thanks. And, uh, you- you ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>Alright. Take Care. [SEP] You too. [SEP]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/val/Ses...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15867 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               utterance    label  \\\n",
       "0       [SEP] OK, we got the cole slaw, we got the bu...  neutral   \n",
       "1      OK, we got the cole slaw, we got the buns... [...  disgust   \n",
       "2      We've got the ground-up flesh of formerly cute...  neutral   \n",
       "3       [SEP] Wait a minute, hold it.  Johnson! Will ...  neutral   \n",
       "4      Wait a minute, hold it.  Johnson! Will you com...  neutral   \n",
       "...                                                  ...      ...   \n",
       "15863  God, that's like a whole problem with like-- B...  neutral   \n",
       "15864  if you ever come out to Montgomery, I mean, yo...  neutral   \n",
       "15865  I'll [SEP] call up the Sprint call center and,...  neutral   \n",
       "15866  Wow, alright. Well, thanks. And, uh, you- you ...  neutral   \n",
       "15867          Alright. Take Care. [SEP] You too. [SEP]   neutral   \n",
       "\n",
       "                                                    path  \n",
       "0      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "1      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "2      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "3      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "4      multimodal-datasets/MELD/raw-audios/train_resa...  \n",
       "...                                                  ...  \n",
       "15863  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "15864  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "15865  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "15866  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "15867  multimodal-datasets/IEMOCAP/raw-audios/val/Ses...  \n",
       "\n",
       "[15867 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "44524827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SEP] Brian, I need help. [SEP] Babe, I don't...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian, I need help. [SEP] Babe, I don't know w...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't--I'm just--I'm thinking maybe I should...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well, of course not, but what are you going to...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't know.  I mean, what am I supposed to d...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/IEMOCAP/raw-audios/test/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>Exactly. [SEP] You've tasted it? You've tasted...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>You've tasted it? You've tasted it. [SEP] Uh h...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>Uh huh. [SEP] Oh, you've tasted it. [SEP] You ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>Oh, you've tasted it. [SEP] You can keep sayin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>You can keep saying it, but it won't stop bein...</td>\n",
       "      <td>anger</td>\n",
       "      <td>multimodal-datasets/MELD/raw-audios/val_resamp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2758 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              utterance     label  \\\n",
       "0      [SEP] Brian, I need help. [SEP] Babe, I don't...   sadness   \n",
       "1     Brian, I need help. [SEP] Babe, I don't know w...   neutral   \n",
       "2     I don't--I'm just--I'm thinking maybe I should...   neutral   \n",
       "3     Well, of course not, but what are you going to...     anger   \n",
       "4     I don't know.  I mean, what am I supposed to d...     anger   \n",
       "...                                                 ...       ...   \n",
       "2754  Exactly. [SEP] You've tasted it? You've tasted...  surprise   \n",
       "2755  You've tasted it? You've tasted it. [SEP] Uh h...   neutral   \n",
       "2756  Uh huh. [SEP] Oh, you've tasted it. [SEP] You ...     anger   \n",
       "2757  Oh, you've tasted it. [SEP] You can keep sayin...   neutral   \n",
       "2758  You can keep saying it, but it won't stop bein...     anger   \n",
       "\n",
       "                                                   path  \n",
       "0     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "1     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "2     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "3     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "4     multimodal-datasets/IEMOCAP/raw-audios/test/Se...  \n",
       "...                                                 ...  \n",
       "2754  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "2755  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "2756  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "2757  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "2758  multimodal-datasets/MELD/raw-audios/val_resamp...  \n",
       "\n",
       "[2758 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5dd5b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True).to_csv(\"train_text_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ca2a6632",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(drop=True).to_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a406207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
